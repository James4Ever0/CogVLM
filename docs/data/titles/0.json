{
    "/README.md": "Introducing CogAgent: Enhanced AI Model with HuggingFace Support",
    "/README.md:1-19": "Intro to CogVLM and CogAgent: README & Dataset Release",
    "/README.md:107-134": "CLI Demo with CogAgent and CogVLM Models",
    "/README.md:135-160": "Efficient SAT Model for Text Generation",
    "/README.md:161-189": "CLI Examples for CogAgent and CogVLM Models",
    "/README.md:19-25": "CogAgent-18B: Advanced Visual Language Model",
    "/README.md:190-219": "Finetuning CogVLM for Tasks with Lora",
    "/README.md:221-253": "Setup and Evaluate Captcha Dataset Model",
    "/README.md:254-287": "Image Request Example Node with Model Inference Requirements",
    "/README.md:26-50": "CogVLM & CogAgent README Table of Contents",
    "/README.md:287-295": "Markdown Models Comparison Table",
    "/README.md:296-299": "CogVLM Model Versions",
    "/README.md:301-334": "Open-Source VLM Powerhouse",
    "/README.md:335-388": "Language Model Performance Metrics Table",
    "/README.md:389-443": "Comparing Language Model Performance: Qwen, DreamLLM, CogVLM",
    "/README.md:444-473": "Model Performance Comparison Chart",
    "/README.md:474-512": "CogAgent: Enhanced Visual Language Model",
    "/README.md:51-67": "New Features & Updates Released",
    "/README.md:513-542": "Advanced AI Agent: CogAgent",
    "/README.md:544-560": "Task-Based Questioning with CogAgent",
    "/README.md:561-579": "Grounded Search: CogVLM on Google",
    "/README.md:581-596": "Image Grounding Model: Description to Bounding Box Coordinates",
    "/README.md:597-619": "Versions and Specifications for Text Processor Models",
    "/README.md:620-640": "Download and Cite CogVLM Model",
    "/README.md:640-660": "GUI Agents Citation and Image-Text Data Sources",
    "/README.md:660-661": "Acknowledging Contributions and Datasets",
    "/README.md:68-81": "Versatile AI Model Updates: CogVLM Enhancements",
    "/README.md:81-105": "Install and Use CogVLM/CogAgent",
    "/basic_demo/cli_demo_hf.py": "CLI Demo with CogAgent and Tokenizer",
    "/basic_demo/cli_demo_hf.py:1-19": "CLI Demo: CogAgent with Quantized 4-bit and Vicuna-7b-v1.5",
    "/basic_demo/cli_demo_hf.py:101-103": "Split and Store History",
    "/basic_demo/cli_demo_hf.py:20-52": "Quantized AutoModel Setup",
    "/basic_demo/cli_demo_hf.py:54-83": "Interactive Chat Loop with Image Support",
    "/basic_demo/cli_demo_hf.py:83-100": "Preparing Data for Model Generation",
    "/basic_demo/cli_demo_sat.py": "Command-Line Text Generation",
    "/basic_demo/cli_demo_sat.py:1-22": "Text Model CLI Demo",
    "/basic_demo/cli_demo_sat.py:121-145": "Command-line Demo for Text Completion",
    "/basic_demo/cli_demo_sat.py:146-161": "Broadcast User Input Across GPUs",
    "/basic_demo/cli_demo_sat.py:22-41": "Command-line Arguments for Language Model",
    "/basic_demo/cli_demo_sat.py:42-58": "Initialize Language and Image Processors",
    "/basic_demo/cli_demo_sat.py:60-87": "CLI Demo Initialization",
    "/basic_demo/cli_demo_sat.py:88-120": "Distributed Chat Command Processor",
    "/basic_demo/web_demo.py": "Gradio-Powered Web Demo",
    "/basic_demo/web_demo.py:1-25": "Web Demo of CogVLM & CogAgent Models",
    "/basic_demo/web_demo.py:126-149": "Function Call to Text Model",
    "/basic_demo/web_demo.py:150-185": "Web Demo: Chatbot UI and Functionality",
    "/basic_demo/web_demo.py:186-204": "Chatbot Image Prompt Interface with AI Control",
    "/basic_demo/web_demo.py:205-222": "AI Text Gen App UI Config",
    "/basic_demo/web_demo.py:223-234": "Command Line Arguments with ArgumentParser",
    "/basic_demo/web_demo.py:28-42": "Module Imports and Variable Definitions",
    "/basic_demo/web_demo.py:42-75": "Quantization Helper for Image Processing",
    "/basic_demo/web_demo.py:76-93": "Deploying Model for Web Demo",
    "/basic_demo/web_demo.py:95-125": "Image-Based AI Chat Function",
    "/composite_demo/client.py": "Efficient Large Language Model Interaction",
    "/composite_demo/client.py:1-30": "Chatbot System Setup and GPU Compatibility",
    "/composite_demo/client.py:121-143": "Model Tokenizer Dictionary Initialization",
    "/composite_demo/client.py:144-167": "Stream-Based Text Responses Generator",
    "/composite_demo/client.py:168-194": "Model Selection and Generation Process",
    "/composite_demo/client.py:195-216": "Streaming Model Inference Setup",
    "/composite_demo/client.py:217-228": "Token Stream Generation Model",
    "/composite_demo/client.py:31-67": "Model Info and Client Creation",
    "/composite_demo/client.py:68-98": "Generate Stream Function and Client Protocol",
    "/composite_demo/client.py:99-120": "Interactive Large Language Model Manager",
    "/composite_demo/conversation.py": "Conversation Class: Multi-language Support and Shape Drawing",
    "/composite_demo/conversation.py:1-34": "Title: \"Conversation Roles Enumeration\"",
    "/composite_demo/conversation.py:115-142": "Three Functions for Conversation AI",
    "/composite_demo/conversation.py:143-169": "Bounding Box Annotation Tool",
    "/composite_demo/conversation.py:170-194": "Draw Shapes on Images with Coordinates",
    "/composite_demo/conversation.py:196-223": "Baidu Translation API Request Function",
    "/composite_demo/conversation.py:224-224": "Final Translated Text Composition",
    "/composite_demo/conversation.py:35-57": "Conversation Turn Class",
    "/composite_demo/conversation.py:59-89": "Conversation WebUI Display: Class and Translation",
    "/composite_demo/conversation.py:90-114": "Error Checking and Conversation Processing",
    "/composite_demo/demo_agent_cogagent.py": "Composite Demo: CogAgent Chat System",
    "/composite_demo/demo_agent_cogagent.py:1-40": "Chatbot Conversation Appender",
    "/composite_demo/demo_agent_cogagent.py:41-65": "Conversation Retrieval and Image Processing",
    "/composite_demo/demo_agent_cogagent.py:67-93": "Chinese Translation Initialization",
    "/composite_demo/demo_agent_cogagent.py:94-119": "Conversation Agent System for CogVLM",
    "/composite_demo/demo_chat_cogagent.py": "Chatbot with Image Processing",
    "/composite_demo/demo_chat_cogagent.py:1-40": "Setting Up Variables and Main Function",
    "/composite_demo/demo_chat_cogagent.py:41-65": "Chat History and Image Comparison",
    "/composite_demo/demo_chat_cogagent.py:66-93": "Chatbot Detects Chinese Characters",
    "/composite_demo/demo_chat_cogagent.py:94-113": "Appending and Updating Conversation History",
    "/composite_demo/demo_chat_cogvlm.py": "Chat Demo Application Initialization and Processing",
    "/composite_demo/demo_chat_cogvlm.py:1-40": "Chat Demo Application Setup",
    "/composite_demo/demo_chat_cogvlm.py:41-65": "Chat History Management and Image Update",
    "/composite_demo/demo_chat_cogvlm.py:66-92": "Conversation Initialization and Translation Check",
    "/composite_demo/demo_chat_cogvlm.py:93-113": "Chatbot Conversation Generator",
    "/composite_demo/main.py": "Chat App with Image Upload and Prompt Adjustments",
    "/composite_demo/main.py:1-23": "CogAgent and CogVLM in WebDEMO Tutorial",
    "/composite_demo/main.py:121-147": "File Upload Check and Module Caller",
    "/composite_demo/main.py:148-153": "Error Check for Images and Tabs",
    "/composite_demo/main.py:24-51": "Composite Chat Demo Setup",
    "/composite_demo/main.py:54-92": "Interactive Image Chat with CogAgent/CogVLM",
    "/composite_demo/main.py:92-120": "Interactive Image-Based Chat App",
    "/composite_demo/utils.py": "Dynamic AI Image Analysis with Prompts and Bounding Boxes",
    "/composite_demo/utils.py:1-35": "Image Comparison and Base64 Encoding Utilities",
    "/composite_demo/utils.py:100-119": "Frequently Asked Task Guidance Questions",
    "/composite_demo/utils.py:120-141": "Image Location Grounding Prompts",
    "/composite_demo/utils.py:142-154": "Find Object Bounding Boxes",
    "/composite_demo/utils.py:155-167": "Bounding Box Location Retrieval Methods",
    "/composite_demo/utils.py:168-181": "Bounding Box Prompt Generator",
    "/composite_demo/utils.py:182-194": "Bounding Box Prompts Code",
    "/composite_demo/utils.py:195-207": "Image Region Descriptions Prompts",
    "/composite_demo/utils.py:208-221": "Region-specific Questions: Image Data Extractor",
    "/composite_demo/utils.py:222-235": "Region Description Prompts",
    "/composite_demo/utils.py:236-249": "Bounding Box Instructions",
    "/composite_demo/utils.py:250-261": "Rectangle Image Descriptions",
    "/composite_demo/utils.py:262-274": "Image Analysis Prompts: Coordinate-based Descriptions",
    "/composite_demo/utils.py:275-287": "Bounding Box Descriptors",
    "/composite_demo/utils.py:288-300": "Bounding Box Prompts",
    "/composite_demo/utils.py:301-313": "Bounding Box Prompt Codes",
    "/composite_demo/utils.py:314-325": "Dynamic Image Prompts",
    "/composite_demo/utils.py:36-58": "Assistance Request Phrases",
    "/composite_demo/utils.py:59-79": "Seeking Guidance and Information",
    "/composite_demo/utils.py:80-99": "Seeking Guidance Prompts",
    "/dataset.md": "Bilingual Visual Instruction Dataset for CogVLM v1.0",
    "/dataset.md:1-11": "Constructing CogVLM-SFT-311K Dataset: Bilingual Visual Instruction Data",
    "/dataset.md:12-40": "Mixed Data Dataset for Minigpt4-3500 and Llava",
    "/dataset.md:41-66": "Dataset Format: Conversations and Image Descriptions",
    "/dataset.md:66-75": "Zebras Seek Shelter in Green Fields",
    "/finetune_demo/evaluate_cogagent.sh": "Accelerated CogAgent Chat Model Training with DeepSpeed",
    "/finetune_demo/evaluate_cogagent.sh:1-34": "Configuring CogAgent Finetuning Environment",
    "/finetune_demo/evaluate_cogagent.sh:35-56": "Accelerating GPT Training with DeepSpeed",
    "/finetune_demo/evaluate_cogagent_demo.py": "Fine-Tune Demo: CogAgent Training",
    "/finetune_demo/evaluate_cogagent_demo.py:1-29": "Tensor Conversion and Concatenation for Lists and Numpy Arrays",
    "/finetune_demo/evaluate_cogagent_demo.py:117-140": "Transformer Model for Text Generation",
    "/finetune_demo/evaluate_cogagent_demo.py:141-167": "Accuracy Evaluation for Text Generation Models",
    "/finetune_demo/evaluate_cogagent_demo.py:169-193": "Autoregressive Model Evaluation and Output Generation",
    "/finetune_demo/evaluate_cogagent_demo.py:194-220": "Forward Pass and Loss Computation",
    "/finetune_demo/evaluate_cogagent_demo.py:221-237": "Dataset Parsing and Setup",
    "/finetune_demo/evaluate_cogagent_demo.py:239-248": "Fine-Tuning CogAgent Model for Evaluation",
    "/finetune_demo/evaluate_cogagent_demo.py:30-51": "Checking Existence of 'cross' Attribute in Images",
    "/finetune_demo/evaluate_cogagent_demo.py:53-82": "Model Arguments Creation and Merging",
    "/finetune_demo/evaluate_cogagent_demo.py:84-116": "Chatbot Output Generator",
    "/finetune_demo/evaluate_cogvlm.sh": "Accelerating CogVLM Fine-Tuning",
    "/finetune_demo/evaluate_cogvlm.sh:1-36": "Fine-tune CogVLM with merged Lora checkpoint",
    "/finetune_demo/evaluate_cogvlm.sh:37-59": "Finetune CogVLM with Evaluation and Deepspeed",
    "/finetune_demo/evaluate_cogvlm_demo.py": "Evaluate COGVLM Demo",
    "/finetune_demo/evaluate_cogvlm_demo.py:1-27": "Fine-tune CogVLM for Data Collation",
    "/finetune_demo/evaluate_cogvlm_demo.py:117-147": "Calculate Accuracy of Model Predictions",
    "/finetune_demo/evaluate_cogvlm_demo.py:148-170": "Data Preprocessing for Autoregressive Model Prediction",
    "/finetune_demo/evaluate_cogvlm_demo.py:171-199": "Forward Step and Dataset Creation in ML Model",
    "/finetune_demo/evaluate_cogvlm_demo.py:200-215": "Preparing Model for Fine-tuning",
    "/finetune_demo/evaluate_cogvlm_demo.py:216-219": "Evaluating Model Performance with Image and Text Processors",
    "/finetune_demo/evaluate_cogvlm_demo.py:28-63": "Preparing Data for ML Model Training",
    "/finetune_demo/evaluate_cogvlm_demo.py:64-91": "Autoregressive Sampling with Chat Function",
    "/finetune_demo/evaluate_cogvlm_demo.py:92-116": "Evaluate Model's Predictions",
    "/finetune_demo/finetune_cogagent_demo.py": "Model Fine-Tuning Demo",
    "/finetune_demo/finetune_cogagent_demo.py:1-26": "Enable Training for Specific Layers",
    "/finetune_demo/finetune_cogagent_demo.py:110-140": "Batch Data Loader and Converter",
    "/finetune_demo/finetune_cogagent_demo.py:141-165": "Token Concatenation and Decoding",
    "/finetune_demo/finetune_cogagent_demo.py:166-195": "Accuracy Metrics Calculator",
    "/finetune_demo/finetune_cogagent_demo.py:196-217": "Fine-Tuning and Generating Outputs",
    "/finetune_demo/finetune_cogagent_demo.py:220-244": "Defining Neural Network Functions",
    "/finetune_demo/finetune_cogagent_demo.py:245-263": "Fine-tune CogAgent Model using Argparse and LoraMixin",
    "/finetune_demo/finetune_cogagent_demo.py:265-278": "Initiate CogAgent Fine-Tuning Model",
    "/finetune_demo/finetune_cogagent_demo.py:27-55": "Filter and Count Trainable Parameters",
    "/finetune_demo/finetune_cogagent_demo.py:279-290": "Model Training and Merging Process",
    "/finetune_demo/finetune_cogagent_demo.py:56-76": "Lists to Tensors and Attribute Extraction",
    "/finetune_demo/finetune_cogagent_demo.py:77-109": "Finetune COG Agent Model Function Code",
    "/finetune_demo/finetune_cogagent_lora.sh": "Finetune CogAgent with LORA and Deepspeed",
    "/finetune_demo/finetune_cogagent_lora.sh:1-36": "CUDA, LD_LIBRARY_PATH Setup for Model Training",
    "/finetune_demo/finetune_cogagent_lora.sh:37-59": "Finetuning CogAgent with Deepspeed and VIT",
    "/finetune_demo/finetune_cogvlm_demo.py": "Finetune CogVLM Chatbot Demo",
    "/finetune_demo/finetune_cogvlm_demo.py:1-29": "Fine-tuning CogVLM with Disable Functions",
    "/finetune_demo/finetune_cogvlm_demo.py:119-142": "Strategic Model Filling Sequence Called",
    "/finetune_demo/finetune_cogvlm_demo.py:143-173": "Case-Sensitive Accuracy Calculator",
    "/finetune_demo/finetune_cogvlm_demo.py:174-196": "Finetune CogVLM Model for Specific Task",
    "/finetune_demo/finetune_cogvlm_demo.py:197-226": "Forward Pass for Language Model Demo",
    "/finetune_demo/finetune_cogvlm_demo.py:227-241": "Command Line Arguments for CogVLM Model Training",
    "/finetune_demo/finetune_cogvlm_demo.py:242-256": "Model Finetuning Demo",
    "/finetune_demo/finetune_cogvlm_demo.py:256-263": "LORA Fine-tuning Demo",
    "/finetune_demo/finetune_cogvlm_demo.py:30-55": "Defining data_collator Function",
    "/finetune_demo/finetune_cogvlm_demo.py:56-91": "Tensor Data Processing Function",
    "/finetune_demo/finetune_cogvlm_demo.py:92-119": "Generate Model Responses",
    "/finetune_demo/finetune_cogvlm_lora.sh": "Fine-tune CogVLM with LORA and Parallelism",
    "/finetune_demo/finetune_cogvlm_lora.sh:1-36": "Finetuning CogVLM with LORA and Parallelism",
    "/finetune_demo/finetune_cogvlm_lora.sh:37-59": "Fine-tuning CogVLM with DeepSpeed and LORA",
    "/finetune_demo/test_config_bf16.json": "BF16 Batch Finetuning Config",
    "/openai_demo/openai_api.py": "FastAPI Chat App with OpenAI Integration",
    "/openai_demo/openai_api.py:1-32": "Library Import and Configuration",
    "/openai_demo/openai_api.py:121-152": "OpenAI API: Model Listing and Response Classes",
    "/openai_demo/openai_api.py:155-185": "Chat Completion Route\n\nExplanation: This title summarizes the creation of a POST route for chat completions, highlighting the main function performed in the given code section",
    "/openai_demo/openai_api.py:186-211": "Streaming Predictions with OpenAI API",
    "/openai_demo/openai_api.py:212-235": "OpenAI Chat Assistant with CogVLM Model",
    "/openai_demo/openai_api.py:236-265": "Text and Image Extraction API",
    "/openai_demo/openai_api.py:266-287": "Message History Processing",
    "/openai_demo/openai_api.py:288-312": "Streaming Conversation Generation with CogVLM",
    "/openai_demo/openai_api.py:313-335": "Prepare Input and Set Streamer for Language Model",
    "/openai_demo/openai_api.py:336-373": "AI-Generated Text with Memory Cleanup",
    "/openai_demo/openai_api.py:34-68": "Model Card Class and FastAPI with GPU Memory Management",
    "/openai_demo/openai_api.py:374-400": "CUDA Device Check and Model Instantiation",
    "/openai_demo/openai_api.py:71-118": "OpenAI Chat Response Generator",
    "/openai_demo/openai_api_request.py": "OpenAI API Chat Simulator",
    "/openai_demo/openai_api_request.py:1-23": "OpenAI API Mimic for CogVLM and CogAgent Chat",
    "/openai_demo/openai_api_request.py:108-119": "OpenAI Chatbot Image Description and Season Query",
    "/openai_demo/openai_api_request.py:24-49": "OpenAI API Request Function",
    "/openai_demo/openai_api_request.py:50-82": "OpenAI API Request and Image Encoding",
    "/openai_demo/openai_api_request.py:83-108": "Chatbot Image Prompting with OpenAI API",
    "/requirements.txt": "Python Project Requirements",
    "/utils/merge_model.py": "Merging and Fine-tuning Model Checkpoint",
    "/utils/merge_model.py:1-27": "Loading and Fine-Tuning Model",
    "/utils/merge_model.py:28-42": "Distributed Model Training and Checkpoint Saving",
    "/utils/models/__init__.py": "Import Models and Functions",
    "/utils/models/cogagent_model.py": "CogAgent Model: Vision Transformer Fine-Tuning",
    "/utils/models/cogagent_model.py:1-27": "GLU Module for CogAgent Model",
    "/utils/models/cogagent_model.py:109-135": "ImageMixin: EVA2CLIP Model Setup",
    "/utils/models/cogagent_model.py:136-155": "Multi-Modal Embedding in COG-VLM Model",
    "/utils/models/cogagent_model.py:157-175": "CogAgent Model: LLaMA-based Image Cognet Model",
    "/utils/models/cogagent_model.py:176-195": "Cross-Attention Model Parameters",
    "/utils/models/cogagent_model.py:196-214": "Fine-tuning CogAgent Model: Class and Initializer",
    "/utils/models/cogagent_model.py:215-229": "Initializing FineTuneTest Model",
    "/utils/models/cogagent_model.py:230-241": "CogAgent Finetune Parser Customization",
    "/utils/models/cogagent_model.py:29-59": "Simplified Model Argument Parsing",
    "/utils/models/cogagent_model.py:60-82": "VIT Model Initialization with External Vision Integration",
    "/utils/models/cogagent_model.py:83-108": "VIT Model with Position Embedding Initialization",
    "/utils/models/cogvlm_model.py": "Fine-tuning CogVLM with Mixins",
    "/utils/models/cogvlm_model.py:1-25": "CogVLM Language Model Setup",
    "/utils/models/cogvlm_model.py:118-135": "Fine-TuneTrain Model Initialization",
    "/utils/models/cogvlm_model.py:136-151": "Fine-tuning Mixins for CogVLM Model",
    "/utils/models/cogvlm_model.py:152-165": "CogVLM Finetuning Arguments",
    "/utils/models/cogvlm_model.py:26-56": "CogVLM Model Definition",
    "/utils/models/cogvlm_model.py:57-78": "Initialize EVA2CLIP Model",
    "/utils/models/cogvlm_model.py:79-96": "Vision-Guided Word Embedding",
    "/utils/models/cogvlm_model.py:97-117": "CogVLM Model Initialization",
    "/utils/models/eva_clip_L_hf.py": "EvaCLIP and Position Embedding: Vision Transformer Models",
    "/utils/models/eva_clip_L_hf.py:1-20": "Broadcasting Tensor Concatenation",
    "/utils/models/eva_clip_L_hf.py:116-150": "Masking Patches in Input Tensors",
    "/utils/models/eva_clip_L_hf.py:151-189": "DropPath and Mlp: Neural Network Modules",
    "/utils/models/eva_clip_L_hf.py:190-223": "Eva Clip L: Neural Network Layer with Fc, Act, Ffn, Dropout",
    "/utils/models/eva_clip_L_hf.py:21-54": "Rotary Position Embedding Class",
    "/utils/models/eva_clip_L_hf.py:224-254": "Efficient Vision Transformer Model",
    "/utils/models/eva_clip_L_hf.py:255-276": "Initialize MultiHeadAttention Layers",
    "/utils/models/eva_clip_L_hf.py:277-290": "Relative Coordinates Indexing and Labeling",
    "/utils/models/eva_clip_L_hf.py:292-315": "Self-Attention Mechanism Class",
    "/utils/models/eva_clip_L_hf.py:316-340": "Transformer Tensor Processing",
    "/utils/models/eva_clip_L_hf.py:341-364": "Efficient Multi-Head Attention with Dropout",
    "/utils/models/eva_clip_L_hf.py:365-390": "Transformer Block Definition",
    "/utils/models/eva_clip_L_hf.py:391-415": "Transformer Model Class Definition",
    "/utils/models/eva_clip_L_hf.py:416-435": "Defining Forward Function for Transformer Model",
    "/utils/models/eva_clip_L_hf.py:436-460": "Eva Clip L Hf Model: Drop Path MLP Architecture",
    "/utils/models/eva_clip_L_hf.py:461-481": "Relative Position Bias Initialization",
    "/utils/models/eva_clip_L_hf.py:482-501": "Position Bias Table Generation",
    "/utils/models/eva_clip_L_hf.py:502-516": "Initializing Vision Transformer Model",
    "/utils/models/eva_clip_L_hf.py:517-544": "Initializing Transformer Model Attributes",
    "/utils/models/eva_clip_L_hf.py:546-562": "EvaClip: Model Block Creation and Initialization",
    "/utils/models/eva_clip_L_hf.py:55-80": "Efficient Fourier Transform Implementation",
    "/utils/models/eva_clip_L_hf.py:563-589": "Weight Initialization and Dropout Configurator",
    "/utils/models/eva_clip_L_hf.py:590-621": "EvaClip Model Utilities",
    "/utils/models/eva_clip_L_hf.py:622-642": "Linear Layer with Patch Dropout",
    "/utils/models/eva_clip_L_hf.py:643-674": "LayerNorm Subclass with Blocks and Patch Dropout",
    "/utils/models/eva_clip_L_hf.py:675-696": "CLIP Vision Model Config Class",
    "/utils/models/eva_clip_L_hf.py:697-722": "Build Vision Tower in CLIP Model",
    "/utils/models/eva_clip_L_hf.py:723-744": "Initialize EVAVisionTransformer Model",
    "/utils/models/eva_clip_L_hf.py:745-779": "Eva2LargeEncoder: Vision Transformer Features",
    "/utils/models/eva_clip_L_hf.py:780-790": "Cross Vision Model with Eva2LargeEncoder and Position Embedding",
    "/utils/models/eva_clip_L_hf.py:81-115": "Dropout Patches in EvaClip Model",
    "/utils/models/eva_clip_model.py": "Efficient Transformer Model: EVA2CLIP",
    "/utils/models/eva_clip_model.py:1-26": "Self-Attention Mapping Mixin",
    "/utils/models/eva_clip_model.py:100-119": "EVA2CLIP Model Initialization",
    "/utils/models/eva_clip_model.py:120-126": "Configure Argument Groups for EVA2CLIP",
    "/utils/models/eva_clip_model.py:28-52": "Memory-Efficient Attention Functions",
    "/utils/models/eva_clip_model.py:53-79": "Forward Pass: Transformer Layer Attention",
    "/utils/models/eva_clip_model.py:80-99": "Efficient Video Analysis Model",
    "/utils/models/mixin.py": "Transformer Layer Mixins",
    "/utils/models/mixin.py:1-25": "LlamaVisionExpertFCMixin Initialization",
    "/utils/models/mixin.py:111-124": "Tensor Masking Mixin",
    "/utils/models/mixin.py:125-145": "LlamaVisionExpertAttnMixin Class Definition",
    "/utils/models/mixin.py:146-169": "Model Parameters Initialization",
    "/utils/models/mixin.py:170-198": "Linear Layers for Query, Key, and Value Projections",
    "/utils/models/mixin.py:200-221": "Vision Attention Mixin Module Dictionary",
    "/utils/models/mixin.py:222-238": "Separate Language and Vision States",
    "/utils/models/mixin.py:239-256": "Multi-Head Attention with Rotary Embeddings",
    "/utils/models/mixin.py:257-274": "Transformer Model Parallelism with Vision and Language Experts",
    "/utils/models/mixin.py:26-58": "VisionTransformer Layer Configuration",
    "/utils/models/mixin.py:59-88": "Parallel Layers Initialization",
    "/utils/models/mixin.py:89-110": "Vision Expert Transformer Mixin Class",
    "/utils/split_dataset.py": "Dataset Splitter Utilities",
    "/utils/split_dataset.py:1-34": "Shuffle and Split Dataset",
    "/utils/split_dataset.py:35-35": "Task Completion Message",
    "/utils/utils/__init__.py": "Multi-task Utility Module",
    "/utils/utils/chat.py": "Efficient Image Processing Utility",
    "/utils/utils/chat.py:1-30": "Image Data Processor",
    "/utils/utils/chat.py:115-142": "Chat Response Processing and Formatting",
    "/utils/utils/chat.py:143-149": "Process and Parse Response",
    "/utils/utils/chat.py:31-55": "Image Processing Function",
    "/utils/utils/chat.py:56-72": "Data Type Conversion and Device Placement",
    "/utils/utils/chat.py:74-88": "Input Validation and Padding",
    "/utils/utils/chat.py:89-114": "Stream-filling Prediction Modification",
    "/utils/utils/dataset.py": "Custom PyTorch Dataset Loader",
    "/utils/utils/dataset.py:1-29": "Image Text Dataset Generator",
    "/utils/utils/dataset.py:30-60": "Load and Preprocess Images from Data Directory",
    "/utils/utils/dataset.py:61-61": "Dataset Return Function",
    "/utils/utils/grounding_parser.py": "Overlay Images with Text",
    "/utils/utils/grounding_parser.py:1-27": "Box Overlay Image Generator",
    "/utils/utils/grounding_parser.py:28-49": "Text Overlay Image Saving",
    "/utils/utils/grounding_parser.py:50-76": "Noun Phrase Bounding Box Dictionary",
    "/utils/utils/grounding_parser.py:77-86": "Box Position Parser",
    "/utils/utils/language.py": "Tokenization and Preprocessing for Language Models"
}