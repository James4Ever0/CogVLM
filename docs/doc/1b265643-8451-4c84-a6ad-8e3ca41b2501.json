{
    "summary": "The script introduces an OpenAI API simulator for CogVLM and CogAgent Chat, facilitating image and text input via chat function. It initializes a chatbot convo with an image description and a user question, using the OpenAI API to generate a completion based on the given input.",
    "details": [
        {
            "comment": "This script mimics the OpenAI API for CogVLM and CogAgent Chat, integrating image and text input to generate a response. It currently supports single images with the chat model only. The create_chat_completion function sends requests to the chat API based on conversation history.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/openai_demo/openai_api_request.py\":0-22",
            "content": "\"\"\"\nThis script is designed to mimic the OpenAI API interface with CogVLM & CogAgent Chat\nIt demonstrates how to integrate image and text-based input to generate a response.\nCurrently, the model can only handle a single image.\nTherefore, do not use this script to process multiple images in one conversation. (includes images from history)\nAnd it only works on the chat model, not the base model.\n\"\"\"\nimport requests\nimport json\nimport base64\nbase_url = \"http://127.0.0.1:8000\"\ndef create_chat_completion(model, messages, temperature=0.8, max_tokens=2048, top_p=0.8, use_stream=False):\n    \"\"\"\n    This function sends a request to the chat API to generate a response based on the given messages.\n    Args:\n        model (str): The name of the model to use for generating the response.\n        messages (list): A list of message dictionaries representing the conversation history.\n        temperature (float): Controls randomness in response generation. Higher values lead to more random responses.\n        max_tokens (int): The maximum length of the generated response."
        },
        {
            "comment": "This code defines a function that sends an OpenAI API request for chat completion using specified parameters. It constructs a JSON payload with model, messages, stream (whether to use streaming response), max_tokens, temperature, and top_p (diversity control). It then sends a POST request to the API and handles the response as either a single message or a streaming response.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/openai_demo/openai_api_request.py\":23-48",
            "content": "        top_p (float): Controls diversity of response by filtering less likely options.\n        use_stream (bool): Determines whether to use a streaming response or a single response.\n    The function constructs a JSON payload with the specified parameters and sends a POST request to the API.\n    It then handles the response, either as a stream (for ongoing responses) or a single message.\n    \"\"\"\n    data = {\n        \"model\": model,\n        \"messages\": messages,\n        \"stream\": use_stream,\n        \"max_tokens\": max_tokens,\n        \"temperature\": temperature,\n        \"top_p\": top_p,\n    }\n    response = requests.post(f\"{base_url}/v1/chat/completions\", json=data, stream=use_stream)\n    if response.status_code == 200:\n        if use_stream:\n            # \u5904\u7406\u6d41\u5f0f\u54cd\u5e94\n            for line in response.iter_lines():\n                if line:\n                    decoded_line = line.decode('utf-8')[6:]\n                    try:\n                        response_json = json.loads(decoded_line)\n                        content = response_json.get(\"choices\", [{}])[0].get(\"delta\", {}).get(\"content\", \"\")"
        },
        {
            "comment": "Processing API request for OpenAI text completion.\nHandling non-streaming chat responses from OpenAI.\nEncoding an image file into a base64 string using the encode_image function.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/openai_demo/openai_api_request.py\":49-81",
            "content": "                        print(content)\n                    except:\n                        print(\"Special Token:\", decoded_line)\n        else:\n            # \u5904\u7406\u975e\u6d41\u5f0f\u54cd\u5e94\n            decoded_line = response.json()\n            content = decoded_line.get(\"choices\", [{}])[0].get(\"message\", \"\").get(\"content\", \"\")\n            print(content)\n    else:\n        print(\"Error:\", response.status_code)\n        return None\ndef encode_image(image_path):\n    \"\"\"\n    Encodes an image file into a base64 string.\n    Args:\n        image_path (str): The path to the image file.\n    This function opens the specified image file, reads its content, and encodes it into a base64 string.\n    The base64 encoding is used to send images over HTTP as text.\n    \"\"\"\n    with open(image_path, \"rb\") as image_file:\n        return base64.b64encode(image_file.read()).decode(\"utf-8\")\ndef simple_image_chat(use_stream=True, img_path=None):\n    \"\"\"\n    Facilitates a simple chat interaction involving an image.\n    Args:\n        use_stream (bool): Specifies whether to use streaming for chat responses."
        },
        {
            "comment": "This function encodes an image and creates a chat conversation around it, then uses OpenAI's API to generate a response from the model. It includes questions about the image content.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/openai_demo/openai_api_request.py\":82-107",
            "content": "        img_path (str): Path to the image file to be included in the chat.\n    This function encodes the specified image and constructs a predefined conversation involving the image.\n    It then calls `create_chat_completion` to generate a response from the model.\n    The conversation includes asking about the content of the image and a follow-up question.\n    \"\"\"\n    img_url = f\"data:image/jpeg;base64,{encode_image(img_path)}\"\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"text\", \"text\": \"What\u2019s in this image?\",\n                },\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\n                        \"url\": img_url\n                    },\n                },\n            ],\n        },\n        {\n            \"role\": \"assistant\",\n            \"content\": \"The image displays a wooden boardwalk extending through a vibrant green grassy wetland. The sky is partly cloudy with soft, wispy clouds,"
        },
        {
            "comment": "This code initializes a chatbot conversation with an image description and a user question about the season of the photo. It then uses the OpenAI API to create a completion based on the provided input.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/openai_demo/openai_api_request.py\":107-118",
            "content": " indicating nice weather. Vegetation is seen on either side of the boardwalk, and trees are present in the background, suggesting that this area might be a natural reserve or park designed for ecological preservation and outdoor recreation. The boardwalk allows visitors to explore the area without disturbing the natural habitat.\",\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Do you think this is a spring or winter photo?\"\n        },\n    ]\n    create_chat_completion(\"cogvlm-chat-17b\", messages=messages, use_stream=use_stream)\nif __name__ == \"__main__\":\n    simple_image_chat(use_stream=False, img_path=\"demo.jpg\")"
        }
    ]
}