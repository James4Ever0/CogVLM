{
    "summary": "The Conversation class includes attributes for role, content, image, and translation, supports Chinese translations, handles assistant roles, and displays conversation turns. It also provides two functions for prompt generation, post-processing, and text processing using Baidu API for drawing shapes or points on images. The final translated text is returned by combining all translations.",
    "details": [
        {
            "comment": "```python\nimport requests\nimport re\nimport streamlit as st\nfrom dataclasses import dataclass\nfrom enum import auto, Enum\nfrom PIL.Image import Image\nfrom PIL import ImageDraw\nfrom streamlit.delta_generator import DeltaGenerator\nclass Role(Enum):  # This class represents the roles in a conversation for CogVLM and CogAgent applications.\n    \"\"\"\n    There are two roles: USER and ASSISTANT. The USER role is for the user of the system, while the ASSISTANT role is for the AI assistant responding to queries.\n    \"\"\"\n    USER = auto()  # Represents the user role in the conversation.\n    ASSISTANT = auto()  # Represents the assistant role in the conversation.\n    \n    def get_message(self):  # Returns a Streamlit chat message component based on the role.\n        match self.value:\n```",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/conversation.py\":0-33",
            "content": "import requests\nimport re\nimport streamlit as st\nfrom dataclasses import dataclass\nfrom enum import auto, Enum\nfrom PIL.Image import Image\nfrom PIL import ImageDraw\nfrom streamlit.delta_generator import DeltaGenerator\nclass Role(Enum):\n    \"\"\"\n    CogVLM | CogAgent Only have 2 roles: USER, ASSISTANT\n    Represents the roles in a conversation, specifically for CogVLM and CogAgent applications.\n    There are two roles available:\n    - USER: The user of the system, typically the one asking questions or initiating conversation.\n    - ASSISTANT: The system or AI assistant responding to the user's queries.\n    Methods:\n        get_message(self):\n            Retrieves a Streamlit chat message component based on the role. For the USER role, it\n            returns a chat message with the name \"user\" and user avatar. For the ASSISTANT role,\n            it returns a chat message with the name \"assistant\" and assistant avatar.\n    \"\"\"\n    USER = auto()\n    ASSISTANT = auto()\n    def get_message(self):\n        match self.value:"
        },
        {
            "comment": "This code is defining a class called Conversation that represents a single turn in a conversation. The class has attributes for role, content, image, content_show, and translate. It also includes a method (__str__) to return a string representation of the conversation turn with role and content included.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/conversation.py\":34-56",
            "content": "            case Role.USER.value:\n                return st.chat_message(name=\"user\", avatar=\"user\")\n            case Role.ASSISTANT.value:\n                return st.chat_message(name=\"assistant\", avatar=\"assistant\")\n            case _:\n                st.error(f'Unexpected role: {self}')\n@dataclass\nclass Conversation:\n    \"\"\"\n    Represents a single conversation turn within a dialogue.\n    Attributes:\n        role (Role): The role of the speaker in the conversation (USER or ASSISTANT).\n        content (str): The textual content of the conversation turn.\n        image (Image, optional): An optional image associated with the conversation turn.\n        content_show (str, optional): The content to be displayed in the WebUI. This may differ\n            from `content` if translation or other processing is applied.\n        translate \uff08bool, optional): Whether to translate the content of the conversation turn.\n    Methods:\n        __str__(self) -> str:\n            Returns a string representation of the conversation turn, including the role and content."
        },
        {
            "comment": "The code defines a class with `__str__` and `show` methods to display conversation turns in the WebUI. It determines the message style based on role and optionally displays content in a specified Streamlit container. The `show` method also supports translation for Chinese WebUIs if enabled.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/conversation.py\":58-88",
            "content": "        show(self, placeholder: DeltaGenerator | None = None) -> str:\n            Displays the conversation turn in the WebUI. If `placeholder` is provided, the content\n            is shown in the specified Streamlit container. Otherwise, it uses the message style\n            determined by the role.\n    \"\"\"\n    role: Role = Role.USER\n    content: str = \"\"\n    image: Image | None = None\n    content_show: str | None = None\n    translate: bool = False\n    def __str__(self) -> str:\n        print(self.role, self.content)\n        match self.role:\n            case Role.USER | Role.ASSISTANT:\n                return f'{self.role}\\n{self.content}'\n    def show(self, placeholder: DeltaGenerator | None = None) -> str:\n        \"\"\"\n        show in markdown formate\n        \"\"\"\n        if placeholder:\n            message = placeholder\n        else:\n            message = self.role.get_message()\n        # for Chinese WebUI show\n        if self.role == Role.USER:\n            if self.translate:\n                self.content = translate_baidu(self.content_show, source_lan=\"zh\", target_lan=\"en\")"
        },
        {
            "comment": "The code snippet checks if the content is \"error\" and displays an error message. If not, it updates the content accordingly. It then handles the assistant role and translation before setting the formatted content in the message and adding an image if available. The preprocess_text function concatenates conversation turns for further processing.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/conversation.py\":89-113",
            "content": "                if self.content == \"error\":\n                    self.content_show = \"Please Enter your Baidu Translation API Key in function translate_baidu()\"\n            else:\n                self.content = self.content_show\n        if self.role == Role.ASSISTANT:\n            if self.translate:\n                self.content_show = translate_baidu(self.content, source_lan=\"en\", target_lan=\"zh\")\n            else:\n                self.content_show = self.content\n            self.content_show = self.content_show.replace('\\n', '  \\n')\n        message.markdown(self.content_show)\n        if self.image:\n            message.image(self.image)\ndef preprocess_text(history: list[Conversation], ) -> str:\n    \"\"\"\n    Prepares the conversation history for processing by concatenating the content of each turn.\n     Args:\n        history (list[Conversation]): The conversation history, a list of Conversation objects.\n    Returns:\n        str: A single string that concatenates the content of each conversation turn, followed by"
        },
        {
            "comment": "This code defines three functions:\n1. \"get_prompt\" generates a prompt string by concatenating previous conversation history and the role indicator, suitable for input to a text generation model.\n2. \"postprocess_text\" post-processes generated text by incorporating it into a given template, replacing \"<TASK>\" placeholder with the text.\n3. \"postprocess_image\" processes text to identify coordinates for bounding boxes and draws them on the provided image.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/conversation.py\":114-141",
            "content": "        the ASSISTANT role indicator. This string is suitable for use as input to a text generation model.\n    \"\"\"\n    prompt = \"\"\n    for conversation in history:\n        prompt += f'{conversation}'\n    prompt += f'{Role.ASSISTANT}\\n'\n    return prompt\ndef postprocess_text(template: str, text: str) -> str:\n    \"\"\"\n    Post-processes the generated text by incorporating it into a given template.\n    Args:\n        template (str): A template string containing a placeholder for the generated text.\n        text (str): The generated text to be incorporated into the template.\n    Returns:\n        str: The template with the generated text replacing the placeholder.\n    \"\"\"\n    quoted_text = f'\"{text.strip()}\"'\n    return template.replace(\"<TASK>\", quoted_text).strip() if template != \"\" else text.strip()\ndef postprocess_image(text: str, img: Image) -> (str, Image):\n    \"\"\"\n    Processes the given text to identify and draw bounding boxes on the provided image.\n    This function searches for patterns in the text that represent coordinates for bounding"
        },
        {
            "comment": "This function receives a text containing bounding box coordinates and an image, draws rectangles on the image at those coordinates with different colors for distinction, returns processed text with annotations for each bounding box and the image with drawn boxes.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/conversation.py\":142-168",
            "content": "    boxes and draws rectangles on the image at these coordinates. Each box is drawn in a\n    different color for distinction.\n    Args:\n        text (str): The text containing bounding box coordinates in a specific pattern.\n        img (Image): The image on which to draw the bounding boxes.\n    Returns:\n        tuple[str, Image]: The processed text with additional annotations for each bounding\n        box, and the image with the drawn bounding boxes.\n    \"\"\"\n    colors = [\"red\", \"green\", \"blue\", \"yellow\", \"purple\", \"orange\"]\n    # Updated pattern to match single or multiple coordinate groups\n    pattern = r\"\\[\\[([\\d,]+(?:;[\\d,]+)*)\\]\\]\"\n    matches = re.findall(pattern, text)\n    draw = ImageDraw.Draw(img)\n    if not matches:\n        return text, None\n    for i, match in enumerate(matches):\n        # Splitting the matched string into individual coordinate groups\n        coords_groups = match.split(';')\n        # Determining the color for the current match\n        color = colors[i % len(colors)]\n        for coords_str in coords_groups:"
        },
        {
            "comment": "This code is responsible for drawing a shape or point on an image based on the input coordinates. If there are 4 coordinates, it draws a rectangle; if there are 2 coordinates, it draws a point. The coordinates are scaled to fit the image dimensions, and the function returns the text and image after drawing. The translate_baidu function translates text using Baidu's translation service for non-English languages.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/conversation.py\":169-193",
            "content": "            coords = coords_str.split(',')\n            if len(coords) == 4:  # Rectangle\n                scaled_coords = (\n                    int(float(coords[0]) * 0.001 * img.width),\n                    int(float(coords[1]) * 0.001 * img.height),\n                    int(float(coords[2]) * 0.001 * img.width),\n                    int(float(coords[3]) * 0.001 * img.height)\n                )\n                draw.rectangle(scaled_coords, outline=color, width=3)\n            elif len(coords) == 2:  # Point\n                scaled_coords = (\n                    int(float(coords[0]) * 0.001 * img.width),\n                    int(float(coords[1]) * 0.001 * img.height)\n                )\n                radius = 5\n                draw.ellipse([scaled_coords[0] - radius, scaled_coords[1] - radius,\n                              scaled_coords[0] + radius, scaled_coords[1] + radius],\n                             fill=color)\n    return text, img\ndef translate_baidu(translate_text, source_lan, target_lan):\n    \"\"\"\n        Translates text using Baidu's translation service. (if you are not use English)"
        },
        {
            "comment": "This function sends a request to the Baidu translation API to translate text from source language to target language. It takes the text, source language code, and target language code as arguments. Returns translated text or \"error\" in case of exception.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/conversation.py\":195-222",
            "content": "        This function sends a request to the Baidu translation API to translate the provided text\n        from the source language to the target language.\n        Args:\n            translate_text (str): The text to be translated.\n            source_lan (str): The source language code (e.g., \"en\" for English).\n            target_lan (str): The target language code (e.g., \"zh\" for Chinese).\n        Returns:\n            str: The translated text. Returns \"error\" in case of an exception.\n        \"\"\"\n    url = \"https://aip.baidubce.com/rpc/2.0/mt/texttrans/v1?access_token=\"\n    headers = {'Content-Type': 'application/json'}\n    payload = {\n        'q': translate_text,\n        'from': source_lan,\n        'to': target_lan\n    }\n    try:\n        r = requests.post(url, json=payload, headers=headers)\n        result = r.json()\n        final_translation = ''\n        for item in result['result']['trans_result']:\n            final_translation += item['dst'] + '\\n'\n    except Exception as e:\n        print(e)\n        return \"error\""
        },
        {
            "comment": "This line returns the final translated text after combining all translations.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/conversation.py\":223-223",
            "content": "    return final_translation"
        }
    ]
}