{
    "summary": "This code initializes libraries and functions for a chat demo application, manages chat history, handles user input, adjusts image changes, initializes a Conversation object, checks for Chinese characters in prompt_text, appends conversation to history, generates assistant's response based on user input, and processes images.",
    "details": [
        {
            "comment": "Initialize necessary libraries and functions for chat demo application.\nDefine function to append conversation history and display it.\nMain function initializes chat history, handles user input, and manages chat session state.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/demo_chat_cogvlm.py\":0-39",
            "content": "import streamlit as st\nimport base64\nimport re\nfrom PIL import Image\nfrom io import BytesIO\nfrom streamlit.delta_generator import DeltaGenerator\nfrom client import get_client\nfrom utils import images_are_same\nfrom conversation import Conversation, Role, postprocess_image, postprocess_text\nclient = get_client()\ndef append_conversation(\n        conversation: Conversation,\n        history: list[Conversation],\n        placeholder: DeltaGenerator | None = None,\n) -> None:\n    history.append(conversation)\n    conversation.show(placeholder)\ndef main(\n        top_p: float = 0.8,\n        temperature: float = 0.95,\n        prompt_text: str = \"\",\n        metadata: str = \"\",\n        top_k: int = 2,\n        max_new_tokens: int = 2048,\n        grounding: bool = False,\n        retry: bool = False,\n        template: str = \"\",\n):\n    if 'chat_history' not in st.session_state:\n        st.session_state.chat_history = []\n    if prompt_text == \"\" and retry == False:\n        print(\"\\n== Clean ==\\n\")\n        st.session_state.chat_history = []"
        },
        {
            "comment": "This code retrieves and displays the chat history, then checks if there's a need to reload the prompt from the last user conversation. If so, it removes that conversation from the history list. Then it checks if the image has changed since the last user input and adjusts the image accordingly.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/demo_chat_cogvlm.py\":40-64",
            "content": "        return\n    history: list[Conversation] = st.session_state.chat_history\n    for conversation in history:\n        conversation.show()\n    if retry:\n        last_user_conversation_idx = None\n        for idx, conversation in enumerate(history):\n            if conversation.role == Role.USER:\n                last_user_conversation_idx = idx\n        if last_user_conversation_idx is not None:\n            prompt_text = history[last_user_conversation_idx].content_show\n            del history[last_user_conversation_idx:]\n    if prompt_text:\n        image = Image.open(BytesIO(base64.b64decode(metadata))).convert('RGB') if metadata else None\n        image.thumbnail((1120, 1120))\n        image_input = image\n        if history and image:\n            last_user_image = next(\n                (conv.image for conv in reversed(history) if conv.role == Role.USER and conv.image), None)\n            if last_user_image and images_are_same(image, last_user_image):\n                image_input = None\n            else:\n                st.session_state.chat_history = []"
        },
        {
            "comment": "This code is initializing a Conversation object for the User and setting up the prompt_text or template as content to be used in the conversation. It also checks if the prompt_text contains any Chinese characters (if it does, translate will be set to True). The Conversation object is then appended to the history list and a placeholder is created for the Assistant's response.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/demo_chat_cogvlm.py\":65-91",
            "content": "                history = []\n        # Set conversation\n        if re.search('[\\u4e00-\\u9fff]', prompt_text):\n            translate = True\n        else:\n            translate = False\n        user_conversation = Conversation(\n            role=Role.USER,\n            translate=translate,\n            content_show=prompt_text.strip() if retry else postprocess_text(template=template,\n                                                                            text=prompt_text.strip()),\n            image=image_input\n        )\n        append_conversation(user_conversation, history)\n        placeholder = st.empty()\n        assistant_conversation = placeholder.chat_message(name=\"assistant\", avatar=\"assistant\")\n        assistant_conversation = assistant_conversation.empty()\n        # steam Answer\n        output_text = ''\n        for response in client.generate_stream(\n                model_use='vlm_grounding' if grounding else 'vlm_chat',\n                grounding=False,\n                history=history,\n                do_sample=True,"
        },
        {
            "comment": "This code generates a response based on user input and appends the conversation to the chat history. It also outputs the generated text, processes any images, and creates a new assistant conversation object with the processed content.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/demo_chat_cogvlm.py\":92-112",
            "content": "                max_new_tokens=max_new_tokens,\n                temperature=temperature,\n                top_p=top_p,\n                top_k=top_k,\n        ):\n            output_text += response.token.text\n            assistant_conversation.markdown(output_text.strip() + '\u258c')\n        print(\"\\n==Output:==\\n\", output_text)\n        content_output, image_output = postprocess_image(output_text, image)\n        assistant_conversation = Conversation(\n            role=Role.ASSISTANT,\n            content=content_output,\n            image=image_output,\n            translate=translate\n        )\n        append_conversation(\n            conversation=assistant_conversation,\n            history=history,\n            placeholder=placeholder.chat_message(name=\"assistant\", avatar=\"assistant\")\n        )"
        }
    ]
}