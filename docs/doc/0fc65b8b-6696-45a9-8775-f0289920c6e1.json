{
    "summary": "The code is for a chat application using CogAgent and CogVLM models, allowing users to upload images and adjust prompts. It offers different modes of operation, checks for valid file uploads, and displays error messages if necessary.",
    "details": [
        {
            "comment": "This code demonstrates the usage of CogAgent and CogVLM in WebDEMO, utilizing vicuna-7b-v1.5 tokenizer model. It explains that only one image can be processed per conversation and provides user operation logic for Chat and Agent tasks.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/main.py\":0-22",
            "content": "\"\"\"\nThis is a demo using the chat version about CogAgent and CogVLM in WebDEMO\nMake sure you have installed the vicuna-7b-v1.5 tokenizer model (https://huggingface.co/lmsys/vicuna-7b-v1.5),\nand a full checkpoint of vicuna-7b-v1.5 LLM is not required.\nMention that only one image can be processed in a conversation, which means you cannot replace or insert another image\nduring the conversation.\nThe models_info parameter is explained as follows\n   tokenizer: tokenizer model using vicuna-7b-v1.5 model\n   agent_chat: Use the CogAgent-chat-18B model to complete the conversation task\n   vlm_chat: Use the CogVLM-chat-17B model to complete the conversation task\n   vlm_grounding: Use CogVLM-grounding-17B model to complete the Grounding task\nWeb Demo user operation logic is as follows:\n    CogVLM-Chat -> grounding? - yes -> Choose a template -> CogVLM-grounding-17B\n                              - no  -> CogVLM-chat-17B (without grounding)\n    CogAgent-Chat  -> CogAgent-chat-18B (Only QA,without Grounding)\n    CogAgent-Agent -> CogAgent-chat-18B"
        },
        {
            "comment": "This code sets up the page configuration and provides options for different chat demo modes using CogVLM and CogAgent models.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/main.py\":23-50",
            "content": "                   -> Choose a template -> grounding? - yes -> prompt + (with grounding)\n                                                      - no  -> prompt\n    CogAgent-vqa-hf are not included in this demo, but you can use it in the same way as CogAgent-chat-18B\n    and used it in CogAgent-Chat\n\"\"\"\nimport streamlit as st\nst.set_page_config(\n    page_title=\"CogVLM & CogAgent Demo\",\n    page_icon=\":robot:\",\n    layout='centered',\n    initial_sidebar_state='expanded',\n)\nfrom enum import Enum\nfrom utils import encode_file_to_base64, templates_agent_cogagent, template_grounding_cogvlm\nimport demo_chat_cogvlm, demo_agent_cogagent, demo_chat_cogagent\nst.markdown(\"<h3>CogAgent & CogVLM Chat Demo</h3>\", unsafe_allow_html=True)\nst.markdown(\n    \"<sub>\u66f4\u591a\u4f7f\u7528\u65b9\u6cd5\u8bf7\u53c2\u8003\u6587\u6863: https://lslfd0slxc.feishu.cn/wiki/WvQbwIJ9tiPAxGk8ywDck6yfnof \\n\\n \u8bf7\u6839\u636e\u6587\u6863\u7684\u5f15\u5bfc\u8bf4\u660e\u6765\u5c1d\u8bd5demo\uff0c\u4ee5\u4fbf\u7406\u89e3demo\u7684\u5e03\u5c40\u8bbe\u8ba1 </sub> \\n\",\n    unsafe_allow_html=True)\nclass Mode(str, Enum):\n    CogVLM_Chat, CogAgent_Chat, CogAgent_Agent = '\ud83d\udcacCogVLM-Chat', '\ud83e\uddd1\u200d\ud83d\udcbb CogAgent-Chat', '\ud83d\udca1 CogAgent-Agent'"
        },
        {
            "comment": "This code is for a chat application that interacts with the CogAgent or CogVLM model. It allows users to upload an image, adjust prompt parameters like top_p, temperature, and output length, and interact with a chat interface. The code also includes features to clear history, retry exporting, and select between different modes of operation (CogVLM_Chat, CogAgent_Chat).",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/main.py\":53-91",
            "content": "with st.sidebar:\n    top_p = st.slider(\n        'top_p', 0.0, 1.0, 0.8, step=0.01\n    )\n    temperature = st.slider(\n        'temperature', 0.01, 1.0, 0.90, step=0.01\n    )\n    top_k = st.slider(\n        'top_k', 1, 20, 5, step=1\n    )\n    max_new_token = st.slider(\n        'Output length', 1, 2048, 2048, step=1\n    )\n    uploaded_file = st.file_uploader(\"Choose an image...\", type=['.jpg', '.png', '.jpeg'], accept_multiple_files=False)\n    cols = st.columns(2)\n    export_btn = cols[0]\n    clear_history = cols[1].button(\"Clear History\", use_container_width=True)\n    retry = export_btn.button(\"Retry\", use_container_width=True)\nprompt_text = st.chat_input(\n    'Chat with CogAgent | CogVLM',\n    key='chat_input',\n)\ntab = st.radio(\n    'Mode',\n    [mode.value for mode in Mode],\n    horizontal=True,\n    label_visibility='hidden',\n)\nselected_template_grounding_cogvlm = \"\"\nwith st.sidebar:\n    grounding = st.checkbox(\"Grounding\")\n    if tab == Mode.CogVLM_Chat or tab == Mode.CogAgent_Chat:\n        if grounding:\n            se"
        },
        {
            "comment": "Code snippet is a part of an interactive application where the user can choose between different models (CogVLM_Chat and CogAgent_Chat) and provide an image to generate chat responses. The selected template for grounding and agent are also chosen by the user in a sidebar menu. If no file is uploaded, it displays an error message asking the user to upload an image.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/main.py\":91-119",
            "content": "lected_template_grounding_cogvlm = st.selectbox(\"Template For Grounding\", template_grounding_cogvlm)\nif tab == Mode.CogAgent_Agent:\n    with st.sidebar:\n        selected_template_agent_cogagent = st.selectbox(\"Template For Agent\", templates_agent_cogagent)\nif clear_history or retry:\n    prompt_text = \"\"\nmatch tab:\n    case Mode.CogVLM_Chat:\n        st.info(\"This option uses cogvlm-chat and cogvlm-grounding model.\")\n        if uploaded_file is not None:\n            demo_chat_cogvlm.main(\n                retry=retry,\n                top_p=top_p,\n                top_k=top_k,\n                temperature=temperature,\n                prompt_text=prompt_text,\n                metadata=encode_file_to_base64(uploaded_file),\n                max_new_tokens=max_new_token,\n                grounding=grounding,\n                template=selected_template_grounding_cogvlm\n            )\n        else:\n            st.error(f'Please upload an image to start')\n    case Mode.CogAgent_Chat:\n        st.info(\"This option uses cogagent-chat model.\")"
        },
        {
            "comment": "This code checks if an uploaded file is provided. If it is, it calls the main function of either the composite_demo or cogagent_agent module based on the Mode. If not, it displays an error message to prompt the user to upload a file. The main function takes various parameters including the encoded metadata of the uploaded file.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/main.py\":120-146",
            "content": "        if uploaded_file is not None:\n            demo_chat_cogagent.main(\n                retry=retry,\n                top_p=top_p,\n                top_k=top_k,\n                temperature=temperature,\n                prompt_text=prompt_text,\n                metadata=encode_file_to_base64(uploaded_file),\n                max_new_tokens=max_new_token,\n                grounding=grounding,\n                template=selected_template_grounding_cogvlm\n            )\n        else:\n            st.error(f'Please upload an image to start')\n    case Mode.CogAgent_Agent:\n        st.info(\"This option uses cogagent-chat model with agent template.\")\n        if uploaded_file is not None:\n            demo_agent_cogagent.main(\n                retry=retry,\n                top_p=top_p,\n                top_k=top_k,\n                temperature=temperature,\n                prompt_text=prompt_text,\n                metadata=encode_file_to_base64(uploaded_file),\n                max_new_tokens=max_new_token,\n                grounding=grounding,"
        },
        {
            "comment": "This code checks if an image has been uploaded. If not, it displays an error message. If a tab other than \"tab0\" or \"tab1\" is selected, it also displays an error message.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/main.py\":147-152",
            "content": "                template=selected_template_agent_cogagent\n            )\n        else:\n            st.error(f'Please upload an image to start')\n    case _:\n        st.error(f'Unexpected tab: {tab}')"
        }
    ]
}