{
    "summary": "The code establishes the main function, manages user input in a chat application, and handles displaying conversation history and image processing. It also initializes a Chinese-based chat model stream and generates responses.",
    "details": [
        {
            "comment": "Initialize variables and set up the main function.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/demo_chat_cogagent.py\":0-39",
            "content": "import streamlit as st\nimport base64\nimport re\nfrom PIL import Image\nfrom io import BytesIO\nfrom streamlit.delta_generator import DeltaGenerator\nfrom client import get_client\nfrom utils import images_are_same\nfrom conversation import Conversation, Role, postprocess_image, postprocess_text\nclient = get_client()\ndef append_conversation(\n        conversation: Conversation,\n        history: list[Conversation],\n        placeholder: DeltaGenerator | None = None,\n) -> None:\n    history.append(conversation)\n    conversation.show(placeholder)\ndef main(\n        top_p: float = 0.8,\n        temperature: float = 0.95,\n        prompt_text: str = \"\",\n        metadata: str = \"\",\n        top_k: int = 2,\n        max_new_tokens: int = 2048,\n        grounding: bool = False,\n        retry: bool = False,\n        template: str = \"\",\n):\n    if 'chat_history' not in st.session_state:\n        st.session_state.chat_history = []\n    if prompt_text == \"\" and retry == False:\n        print(\"\\n== Clean ==\\n\")\n        st.session_state.chat_history = []"
        },
        {
            "comment": "This code is responsible for displaying the conversation history and handling user input in a chat application. It also checks if there's an existing image input from the user, compares it with the previous one, and decides whether to add a new image or not.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/demo_chat_cogagent.py\":40-64",
            "content": "        return\n    history: list[Conversation] = st.session_state.chat_history\n    for conversation in history:\n        conversation.show()\n    if retry:\n        last_user_conversation_idx = None\n        for idx, conversation in enumerate(history):\n            if conversation.role == Role.USER:\n                last_user_conversation_idx = idx\n        if last_user_conversation_idx is not None:\n            prompt_text = history[last_user_conversation_idx].content_show\n            del history[last_user_conversation_idx:]\n    if prompt_text:\n        image = Image.open(BytesIO(base64.b64decode(metadata))).convert('RGB') if metadata else None\n        image.thumbnail((1120, 1120))\n        image_input = image\n        if history and image:\n            last_user_image = next(\n                (conv.image for conv in reversed(history) if conv.role == Role.USER and conv.image), None)\n            if last_user_image and images_are_same(image, last_user_image):\n                image_input = None\n            else:\n                st.session_state.chat_history = []"
        },
        {
            "comment": "This code initializes a conversation object based on whether the input text contains Chinese characters. It then adds it to the conversation history and sets up a stream for generating a response using a chat model.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/demo_chat_cogagent.py\":65-92",
            "content": "                history = []\n        # Set conversation\n        if re.search('[\\u4e00-\\u9fff]', prompt_text):\n            translate = True\n        else:\n            translate = False\n        user_conversation = Conversation(\n            role=Role.USER,\n            translate=translate,\n            content_show=prompt_text.strip() if retry else postprocess_text(template=template,\n                                                                            text=prompt_text.strip()),\n            image=image_input\n        )\n        append_conversation(user_conversation, history)\n        placeholder = st.empty()\n        assistant_conversation = placeholder.chat_message(name=\"assistant\", avatar=\"assistant\")\n        assistant_conversation = assistant_conversation.empty()\n        # steam Answer\n        output_text = ''\n        for response in client.generate_stream(\n                model_use='agent_chat',\n                grounding=grounding,\n                history=history,\n                do_sample=True,\n                max_new_tokens=max_new_tokens,"
        },
        {
            "comment": "The code takes the generated response and appends it to the conversation history. It then updates the assistant conversation with the content output, image output, and translate flag if necessary. The function postprocess_image is called to process the output text and image. Finally, the updated assistant conversation is added to the conversation history using append_conversation function.",
            "location": "\"/media/root/Toshiba XG3/works/CogVLM/docs/src/composite_demo/demo_chat_cogagent.py\":93-112",
            "content": "                temperature=temperature,\n                top_p=top_p,\n                top_k=top_k,\n        ):\n            output_text += response.token.text\n            assistant_conversation.markdown(output_text.strip() + '\u258c')\n        print(\"\\n==Output:==\\n\", output_text)\n        content_output, image_output = postprocess_image(output_text, image)\n        assistant_conversation = Conversation(\n            role=Role.ASSISTANT,\n            content=content_output,\n            image=image_output,\n            translate=translate\n        )\n        append_conversation(\n            conversation=assistant_conversation,\n            history=history,\n            placeholder=placeholder.chat_message(name=\"assistant\", avatar=\"assistant\")\n        )"
        }
    ]
}