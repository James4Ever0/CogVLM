{"_default": {"1": {"path": "/README.md", "hash": "da6cc014bf3fdb39750516e4ff6ef105", "title": "Introducing CogAgent: Enhanced AI Model with HuggingFace Support"}, "2": {"path": "/README.md:1-19", "hash": "b3ce27c9a0a7f96af64d0520248ee02d", "title": "Intro to CogVLM and CogAgent: README & Dataset Release"}, "3": {"path": "/README.md:19-25", "hash": "fa201d8fc23396257a9305843e8a4fc9", "title": "CogAgent-18B: Advanced Visual Language Model"}, "4": {"path": "/README.md:26-50", "hash": "7a0d1821087d670a869652e335b5fbda", "title": "CogVLM & CogAgent README Table of Contents"}, "5": {"path": "/README.md:51-67", "hash": "bb0cb8971efa2d9bbfea36c26b52b012", "title": "New Features & Updates Released"}, "6": {"path": "/README.md:68-81", "hash": "3ef1b32ab6f61330070eae77eee522aa", "title": "Versatile AI Model Updates: CogVLM Enhancements"}, "7": {"path": "/README.md:81-105", "hash": "a36a36d095e1925839c7f51138a1694a", "title": "Install and Use CogVLM/CogAgent"}, "8": {"path": "/README.md:107-134", "hash": "31fe84b6ceef503525a060cb9167a9a4", "title": "CLI Demo with CogAgent and CogVLM Models"}, "9": {"path": "/README.md:135-160", "hash": "42bb9b4e2ed4284f09d8d574e5a1f66f", "title": "Efficient SAT Model for Text Generation"}, "10": {"path": "/README.md:161-189", "hash": "fb148297288aff59115002cb02a5c8e6", "title": "CLI Examples for CogAgent and CogVLM Models"}, "11": {"path": "/README.md:190-219", "hash": "7de7ec351168f9e78c459fd682a1e53e", "title": "Finetuning CogVLM for Tasks with Lora"}, "12": {"path": "/README.md:221-253", "hash": "3cc27e776cb598c0714112a210369c51", "title": "Setup and Evaluate Captcha Dataset Model"}, "13": {"path": "/README.md:254-287", "hash": "a7b040707f614ac427c384fa97ed274a", "title": "Image Request Example Node with Model Inference Requirements"}, "14": {"path": "/README.md:287-295", "hash": "f30dcd0f15230445e04e1b8fc7f2ec52", "title": "Markdown Models Comparison Table"}, "15": {"path": "/README.md:296-299", "hash": "118ca0e418fd6cee1aca758206f7b453", "title": "CogVLM Model Versions"}, "16": {"path": "/README.md:301-334", "hash": "14c23c55f23e9605ea8d48876b7d7452", "title": "Open-Source VLM Powerhouse"}, "17": {"path": "/README.md:335-388", "hash": "74dda5e87a39d3c4c511c98c06212b74", "title": "Language Model Performance Metrics Table"}, "18": {"path": "/README.md:389-443", "hash": "479db141e336897f704bb0a4cbb7f8cc", "title": "Comparing Language Model Performance: Qwen, DreamLLM, CogVLM"}, "19": {"path": "/README.md:444-473", "hash": "e024de36256b163a0bf3c2f2a78cbb48", "title": "Model Performance Comparison Chart"}, "20": {"path": "/README.md:474-512", "hash": "dcca7f8023777bf0be6db8516468ea21", "title": "CogAgent: Enhanced Visual Language Model"}, "21": {"path": "/README.md:513-542", "hash": "8eaedb4710b2f142bb7050f3c82d452b", "title": "Advanced AI Agent: CogAgent"}, "22": {"path": "/README.md:544-560", "hash": "7551c94d105f82819a1f2fbaf3e7b2e0", "title": "Task-Based Questioning with CogAgent"}, "23": {"path": "/README.md:561-579", "hash": "2b3187a907f84fd9e344c4f559a3dbd9", "title": "Grounded Search: CogVLM on Google"}, "24": {"path": "/README.md:581-596", "hash": "7bf0c932f2c72e1c440e9d7435e1ec1c", "title": "Image Grounding Model: Description to Bounding Box Coordinates"}, "25": {"path": "/README.md:597-619", "hash": "8b207b7c2d308aa43bf103574e6aceca", "title": "Versions and Specifications for Text Processor Models"}, "26": {"path": "/README.md:620-640", "hash": "ba482fbb003441f74021a4dcd339be84", "title": "Download and Cite CogVLM Model"}, "27": {"path": "/README.md:640-660", "hash": "105fb73c1a549a32637b94ba3c0bc360", "title": "GUI Agents Citation and Image-Text Data Sources"}, "28": {"path": "/README.md:660-661", "hash": "699d45c9ab25d01ec2663d618281edb5", "title": "Acknowledging Contributions and Datasets"}, "29": {"path": "/basic_demo/cli_demo_hf.py", "hash": "06b8da73cac09b30d9f1204b4f564a57", "title": "CLI Demo with CogAgent and Tokenizer"}, "30": {"path": "/basic_demo/cli_demo_hf.py:1-19", "hash": "4e8cd4f1b266844f8651b1799dcd698b", "title": "CLI Demo: CogAgent with Quantized 4-bit and Vicuna-7b-v1.5"}, "31": {"path": "/basic_demo/cli_demo_hf.py:20-52", "hash": "802f595781b13837dd24c5fc392bed1f", "title": "Quantized AutoModel Setup"}, "32": {"path": "/basic_demo/cli_demo_hf.py:54-83", "hash": "2fd4e4d1822aafa5a8686eb49510e6a1", "title": "Interactive Chat Loop with Image Support"}, "33": {"path": "/basic_demo/cli_demo_hf.py:83-100", "hash": "1e414861c00f3d010555ef1347d15eb0", "title": "Preparing Data for Model Generation"}, "34": {"path": "/basic_demo/cli_demo_hf.py:101-103", "hash": "da08a706ce68c8c05d49461a507c704c", "title": "Split and Store History"}, "35": {"path": "/basic_demo/cli_demo_sat.py", "hash": "1d25bcdd40e2b16b6cf7f401877dc988", "title": "Command-Line Text Generation"}, "36": {"path": "/basic_demo/cli_demo_sat.py:1-22", "hash": "14bc4e8226410f66e093ad984b227b54", "title": "Text Model CLI Demo"}, "37": {"path": "/basic_demo/cli_demo_sat.py:22-41", "hash": "889f8374e1b44377e1f2ee982146d538", "title": "Command-line Arguments for Language Model"}, "38": {"path": "/basic_demo/cli_demo_sat.py:42-58", "hash": "90464e2d19f73a64ed3b4c8e3f522a4d", "title": "Initialize Language and Image Processors"}, "39": {"path": "/basic_demo/cli_demo_sat.py:60-87", "hash": "d75d4ee2fd364892a382bf3d34636f2b", "title": "CLI Demo Initialization"}, "40": {"path": "/basic_demo/cli_demo_sat.py:88-120", "hash": "d762dc575516fba7f205f782e1279247", "title": "Distributed Chat Command Processor"}, "41": {"path": "/basic_demo/cli_demo_sat.py:121-145", "hash": "dcd9c3a8f47784c4c32e21c389485c99", "title": "Command-line Demo for Text Completion"}, "42": {"path": "/basic_demo/cli_demo_sat.py:146-161", "hash": "029b91d5d47ee1a015df84eeaaf54711", "title": "Broadcast User Input Across GPUs"}, "43": {"path": "/basic_demo/web_demo.py", "hash": "809ebaf5f0f11c1bd89ba8f47cce173c", "title": "Gradio-Powered Web Demo"}, "44": {"path": "/basic_demo/web_demo.py:1-25", "hash": "9b504c3564cc1c9f9b627c9b12b62fbf", "title": "Web Demo of CogVLM & CogAgent Models"}, "45": {"path": "/basic_demo/web_demo.py:28-42", "hash": "ff1999ef33f6aacfdd81d46b2070022d", "title": "Module Imports and Variable Definitions"}, "46": {"path": "/basic_demo/web_demo.py:42-75", "hash": "920016c3f3ae2730cc1828873548c237", "title": "Quantization Helper for Image Processing"}, "47": {"path": "/basic_demo/web_demo.py:76-93", "hash": "1609ab338faba79c9998992e84d8e0e5", "title": "Deploying Model for Web Demo"}, "48": {"path": "/basic_demo/web_demo.py:95-125", "hash": "a1fca0b85df193459aa788efdc4cbabb", "title": "Image-Based AI Chat Function"}, "49": {"path": "/basic_demo/web_demo.py:126-149", "hash": "6924d4d9e7fc712cfaec980e84b30a29", "title": "Function Call to Text Model"}, "50": {"path": "/basic_demo/web_demo.py:150-185", "hash": "b1578ce1f5cc42c102f886df1d531ec0", "title": "Web Demo: Chatbot UI and Functionality"}, "51": {"path": "/basic_demo/web_demo.py:186-204", "hash": "ad97f9d8c633585e0860feed0639137d", "title": "Chatbot Image Prompt Interface with AI Control"}, "52": {"path": "/basic_demo/web_demo.py:205-222", "hash": "316207ac059abf21078b355af38fcf83", "title": "AI Text Gen App UI Config"}, "53": {"path": "/basic_demo/web_demo.py:223-234", "hash": "0ebc202c0c09459f7b46f29501d47ba8", "title": "Command Line Arguments with ArgumentParser"}, "54": {"path": "/composite_demo/client.py", "hash": "dc8148f1aad720e0d89e05d66a977d82", "title": "Efficient Large Language Model Interaction"}, "55": {"path": "/composite_demo/client.py:1-30", "hash": "e99ae3b405b0502ba2b64d6cfd9392a7", "title": "Chatbot System Setup and GPU Compatibility"}, "56": {"path": "/composite_demo/client.py:31-67", "hash": "41c9ff2a702702b78809d1c61ef56e48", "title": "Model Info and Client Creation"}, "57": {"path": "/composite_demo/client.py:68-98", "hash": "cdf165a540967c3fbc60798407192fab", "title": "Generate Stream Function and Client Protocol"}, "58": {"path": "/composite_demo/client.py:99-120", "hash": "5543d31de6b23813a99a57d4d7bf785a", "title": "Interactive Large Language Model Manager"}, "59": {"path": "/composite_demo/client.py:121-143", "hash": "3c74fa26a108ea6ec64bb5a400709dcf", "title": "Model Tokenizer Dictionary Initialization"}, "60": {"path": "/composite_demo/client.py:144-167", "hash": "8e68c407763d7671be39d5f4ae6a0d0c", "title": "Stream-Based Text Responses Generator"}, "61": {"path": "/composite_demo/client.py:168-194", "hash": "b879734f98aee910c2a29543ad8fd866", "title": "Model Selection and Generation Process"}, "62": {"path": "/composite_demo/client.py:195-216", "hash": "0c8e93dde1ea7163f74b7d93c556c4ab", "title": "Streaming Model Inference Setup"}, "63": {"path": "/composite_demo/client.py:217-228", "hash": "d02aac43406ca6b0a240d458ad5e6807", "title": "Token Stream Generation Model"}, "64": {"path": "/composite_demo/conversation.py", "hash": "53e878da30a53669b193e2d0a993832b", "title": "Conversation Class: Multi-language Support and Shape Drawing"}, "65": {"path": "/composite_demo/conversation.py:1-34", "hash": "22f99b1cb9c869bf7cd90cdd5269b873", "title": "Title: \"Conversation Roles Enumeration\""}, "66": {"path": "/composite_demo/conversation.py:35-57", "hash": "9a1991589fc24edd1c5e8c476ccee682", "title": "Conversation Turn Class"}, "67": {"path": "/composite_demo/conversation.py:59-89", "hash": "ede84f6a2c5625845da02bcf435934d0", "title": "Conversation WebUI Display: Class and Translation"}, "68": {"path": "/composite_demo/conversation.py:90-114", "hash": "08027f013319bb34569f964292d17562", "title": "Error Checking and Conversation Processing"}, "69": {"path": "/composite_demo/conversation.py:115-142", "hash": "61713b69fd053f028570f510f9b1a9e4", "title": "Three Functions for Conversation AI"}, "70": {"path": "/composite_demo/conversation.py:143-169", "hash": "4734065071f90d27214ef115e96c52b9", "title": "Bounding Box Annotation Tool"}, "71": {"path": "/composite_demo/conversation.py:170-194", "hash": "61f89e39782c4c3def87574c8c20cf62", "title": "Draw Shapes on Images with Coordinates"}, "72": {"path": "/composite_demo/conversation.py:196-223", "hash": "b3e25ce23f6783bb5d929862cb9d0132", "title": "Baidu Translation API Request Function"}, "73": {"path": "/composite_demo/conversation.py:224-224", "hash": "ca02ebb9b768be0ec2b948594175972f", "title": "Final Translated Text Composition"}, "74": {"path": "/composite_demo/demo_agent_cogagent.py", "hash": "e894e168c9a66b1cb448585585b07bb8", "title": "Composite Demo: CogAgent Chat System"}, "75": {"path": "/composite_demo/demo_agent_cogagent.py:1-40", "hash": "ed0ff7243defe3634d8247e77bea34f8", "title": "Chatbot Conversation Appender"}, "76": {"path": "/composite_demo/demo_agent_cogagent.py:41-65", "hash": "f5b7d598e4258003e4f1afb1bc5eb04c", "title": "Conversation Retrieval and Image Processing"}, "77": {"path": "/composite_demo/demo_agent_cogagent.py:67-93", "hash": "9b88558d0e208c563b58bb35f2d41b65", "title": "Chinese Translation Initialization"}, "78": {"path": "/composite_demo/demo_agent_cogagent.py:94-119", "hash": "b79fa993a20805bc314c8fbf7ab1ad52", "title": "Conversation Agent System for CogVLM"}, "79": {"path": "/composite_demo/demo_chat_cogagent.py", "hash": "471885d07db103ad3079cf40802c3d15", "title": "Chatbot with Image Processing"}, "80": {"path": "/composite_demo/demo_chat_cogagent.py:1-40", "hash": "6813beaaac2f68925d693fc43ca6515d", "title": "Setting Up Variables and Main Function"}, "81": {"path": "/composite_demo/demo_chat_cogagent.py:41-65", "hash": "9f7b614ab193f7cc197a27c1ec46834a", "title": "Chat History and Image Comparison"}, "82": {"path": "/composite_demo/demo_chat_cogagent.py:66-93", "hash": "9ee79ac62a5df9c9b0cc9723b3e9e1e9", "title": "Chatbot Detects Chinese Characters"}, "83": {"path": "/composite_demo/demo_chat_cogagent.py:94-113", "hash": "476fde7dae8cb3e9dae40739be354c16", "title": "Appending and Updating Conversation History"}, "84": {"path": "/composite_demo/demo_chat_cogvlm.py", "hash": "937f3d89419de22859868467ce1efb26", "title": "Chat Demo Application Initialization and Processing"}, "85": {"path": "/composite_demo/demo_chat_cogvlm.py:1-40", "hash": "040d727a06dc6ea5f0cff1a6173b7d7c", "title": "Chat Demo Application Setup"}, "86": {"path": "/composite_demo/demo_chat_cogvlm.py:41-65", "hash": "79e70f5b10f25603b6b60925fdc250fa", "title": "Chat History Management and Image Update"}, "87": {"path": "/composite_demo/demo_chat_cogvlm.py:66-92", "hash": "8ad0e0b8e98423d94dc2d690fe5b81a6", "title": "Conversation Initialization and Translation Check"}, "88": {"path": "/composite_demo/demo_chat_cogvlm.py:93-113", "hash": "6336ffa0cd890805f26577dab3eadc5d", "title": "Chatbot Conversation Generator"}, "89": {"path": "/composite_demo/main.py", "hash": "90b85ec0fcc10d52d5f9edce36ae6be1", "title": "Chat App with Image Upload and Prompt Adjustments"}, "90": {"path": "/composite_demo/main.py:1-23", "hash": "7b9a3a4e43c4a4b70c07e8a2ef71da76", "title": "CogAgent and CogVLM in WebDEMO Tutorial"}, "91": {"path": "/composite_demo/main.py:24-51", "hash": "27da51f446576ff09315e065ee14f507", "title": "Composite Chat Demo Setup"}, "92": {"path": "/composite_demo/main.py:54-92", "hash": "af6dbc1dd55c13300b1db99b92b2bf85", "title": "Interactive Image Chat with CogAgent/CogVLM"}, "93": {"path": "/composite_demo/main.py:92-120", "hash": "90a0b3c21f10f115c67605a534ab7db4", "title": "Interactive Image-Based Chat App"}, "94": {"path": "/composite_demo/main.py:121-147", "hash": "796fba2564417ddfcf2c430b68b56e89", "title": "File Upload Check and Module Caller"}, "95": {"path": "/composite_demo/main.py:148-153", "hash": "242d3d8e6e957e3676e2dbfa44a28334", "title": "Error Check for Images and Tabs"}, "96": {"path": "/composite_demo/utils.py", "hash": "2581634a7b812516c062eedf51a65533", "title": "Dynamic AI Image Analysis with Prompts and Bounding Boxes"}, "97": {"path": "/composite_demo/utils.py:1-35", "hash": "c78a343cc3410fcd9e0b7699728d1187", "title": "Image Comparison and Base64 Encoding Utilities"}, "98": {"path": "/composite_demo/utils.py:36-58", "hash": "29db4756194de76ca1a65a650150bd83", "title": "Assistance Request Phrases"}, "99": {"path": "/composite_demo/utils.py:59-79", "hash": "6ee5c8accf31267092e230baf56df0f3", "title": "Seeking Guidance and Information"}, "100": {"path": "/composite_demo/utils.py:80-99", "hash": "e13a2232379265f6ccc24be1eb501237", "title": "Seeking Guidance Prompts"}, "101": {"path": "/composite_demo/utils.py:100-119", "hash": "f1476059da73fa5d8f682612c62d48ca", "title": "Frequently Asked Task Guidance Questions"}, "102": {"path": "/composite_demo/utils.py:120-141", "hash": "d761a5d8ac2ab4c1c5224a3205a9aaa4", "title": "Image Location Grounding Prompts"}, "103": {"path": "/composite_demo/utils.py:142-154", "hash": "fafa12a8bf9665cb0b5100787e3eecbc", "title": "Find Object Bounding Boxes"}, "104": {"path": "/composite_demo/utils.py:155-167", "hash": "04fd6ae379a319448d59ba03f55caaf5", "title": "Bounding Box Location Retrieval Methods"}, "105": {"path": "/composite_demo/utils.py:168-181", "hash": "e0226a4931ab51a42df7300178b5fedf", "title": "Bounding Box Prompt Generator"}, "106": {"path": "/composite_demo/utils.py:182-194", "hash": "048b39e5d038ac5a31c00318aed8a300", "title": "Bounding Box Prompts Code"}, "107": {"path": "/composite_demo/utils.py:195-207", "hash": "0cb1bffd8fdeef221ad55b8d8c993b6c", "title": "Image Region Descriptions Prompts"}, "108": {"path": "/composite_demo/utils.py:208-221", "hash": "d736931f4f7eb86cf3053d591ff87e92", "title": "Region-specific Questions: Image Data Extractor"}, "109": {"path": "/composite_demo/utils.py:222-235", "hash": "d5ea053c35b936d6a5be242b4105c14a", "title": "Region Description Prompts"}, "110": {"path": "/composite_demo/utils.py:236-249", "hash": "e3553ee11ca87f55b2c324bcfc7597f5", "title": "Bounding Box Instructions"}, "111": {"path": "/composite_demo/utils.py:250-261", "hash": "9912a399171308f2c62e52f1266b45ce", "title": "Rectangle Image Descriptions"}, "112": {"path": "/composite_demo/utils.py:262-274", "hash": "ec2997f9eedc53646b095564f082e1d3", "title": "Image Analysis Prompts: Coordinate-based Descriptions"}, "113": {"path": "/composite_demo/utils.py:275-287", "hash": "2f9bb5d93c43c9eea3f2bb5df8422eca", "title": "Bounding Box Descriptors"}, "114": {"path": "/composite_demo/utils.py:288-300", "hash": "806259a29f02dc26c65f39c349eeff7b", "title": "Bounding Box Prompts"}, "115": {"path": "/composite_demo/utils.py:301-313", "hash": "3dc593564f9559f9c410e75f37e870e2", "title": "Bounding Box Prompt Codes"}, "116": {"path": "/composite_demo/utils.py:314-325", "hash": "be97de3338b8b5b0374bd4b05caf451c", "title": "Dynamic Image Prompts"}, "117": {"path": "/dataset.md", "hash": "49944a8dd97221dc3a598a4ef2a566f7", "title": "Bilingual Visual Instruction Dataset for CogVLM v1.0"}, "118": {"path": "/dataset.md:1-11", "hash": "67ac77acf874c18fdc58008e6a88b28f", "title": "Constructing CogVLM-SFT-311K Dataset: Bilingual Visual Instruction Data"}, "119": {"path": "/dataset.md:12-40", "hash": "7e3406fb61958d58c4a646d66509c05d", "title": "Mixed Data Dataset for Minigpt4-3500 and Llava"}, "120": {"path": "/dataset.md:41-66", "hash": "fce8570f92ac811bb5af15fb4001dad1", "title": "Dataset Format: Conversations and Image Descriptions"}, "121": {"path": "/dataset.md:66-75", "hash": "0c3292d75942163ecd20c9720ee9362d", "title": "Zebras Seek Shelter in Green Fields"}, "122": {"path": "/finetune_demo/evaluate_cogagent.sh", "hash": "92f499d19dccdd6256ca509c324cf281", "title": "Accelerated CogAgent Chat Model Training with DeepSpeed"}, "123": {"path": "/finetune_demo/evaluate_cogagent.sh:1-34", "hash": "618b17fab099ce5e5785342183b2d6b2", "title": "Configuring CogAgent Finetuning Environment"}, "124": {"path": "/finetune_demo/evaluate_cogagent.sh:35-56", "hash": "762e1369be43854f55a29fa0ae1b43c1", "title": "Accelerating GPT Training with DeepSpeed"}, "125": {"path": "/finetune_demo/evaluate_cogagent_demo.py", "hash": "5a090f1bed6a2670db43556729360140", "title": "Fine-Tune Demo: CogAgent Training"}, "126": {"path": "/finetune_demo/evaluate_cogagent_demo.py:1-29", "hash": "f71e9fcffcb4ba60ef2b3129a664fc4c", "title": "Tensor Conversion and Concatenation for Lists and Numpy Arrays"}, "127": {"path": "/finetune_demo/evaluate_cogagent_demo.py:30-51", "hash": "8ec4872ecf22099c8f64b781fb9937c9", "title": "Checking Existence of 'cross' Attribute in Images"}, "128": {"path": "/finetune_demo/evaluate_cogagent_demo.py:53-82", "hash": "2baa8ad8e619f021896e5a11cce46778", "title": "Model Arguments Creation and Merging"}, "129": {"path": "/finetune_demo/evaluate_cogagent_demo.py:84-116", "hash": "90c2635dd5c4a0d54bc116ffb4bc8046", "title": "Chatbot Output Generator"}, "130": {"path": "/finetune_demo/evaluate_cogagent_demo.py:117-140", "hash": "2fbe046ee2cf048019bd90c37f45ac0d", "title": "Transformer Model for Text Generation"}, "131": {"path": "/finetune_demo/evaluate_cogagent_demo.py:141-167", "hash": "18d8b24a59e7141494defa525ddbd055", "title": "Accuracy Evaluation for Text Generation Models"}, "132": {"path": "/finetune_demo/evaluate_cogagent_demo.py:169-193", "hash": "2c9c177fa5a790d2d3f238e279155bd9", "title": "Autoregressive Model Evaluation and Output Generation"}, "133": {"path": "/finetune_demo/evaluate_cogagent_demo.py:194-220", "hash": "1395338023fa2364d1ac0d12069e751c", "title": "Forward Pass and Loss Computation"}, "134": {"path": "/finetune_demo/evaluate_cogagent_demo.py:221-237", "hash": "3c5f642f40d7b5e07c34c8fef8b16211", "title": "Dataset Parsing and Setup"}, "135": {"path": "/finetune_demo/evaluate_cogagent_demo.py:239-248", "hash": "9926bd20a82f2cac90874828cde5f3b2", "title": "Fine-Tuning CogAgent Model for Evaluation"}, "136": {"path": "/finetune_demo/evaluate_cogvlm.sh", "hash": "6e502bbcae13133255de7283963b42b2", "title": "Accelerating CogVLM Fine-Tuning"}, "137": {"path": "/finetune_demo/evaluate_cogvlm.sh:1-36", "hash": "359bfcfcbb4673ed83b8454af911e84e", "title": "Fine-tune CogVLM with merged Lora checkpoint"}, "138": {"path": "/finetune_demo/evaluate_cogvlm.sh:37-59", "hash": "787d82ebd347b919de95c57d4d062b5b", "title": "Finetune CogVLM with Evaluation and Deepspeed"}, "139": {"path": "/finetune_demo/evaluate_cogvlm_demo.py", "hash": "4b2fcd50b0fae1be3ff67c360be77b17", "title": "Evaluate COGVLM Demo"}, "140": {"path": "/finetune_demo/evaluate_cogvlm_demo.py:1-27", "hash": "68324dcb31a136783f3d2226e8d7ea6a", "title": "Fine-tune CogVLM for Data Collation"}, "141": {"path": "/finetune_demo/evaluate_cogvlm_demo.py:28-63", "hash": "9276ae68535e80bbf11518af6a719a8c", "title": "Preparing Data for ML Model Training"}, "142": {"path": "/finetune_demo/evaluate_cogvlm_demo.py:64-91", "hash": "85822d757db0ead0b0b87771a627ac66", "title": "Autoregressive Sampling with Chat Function"}, "143": {"path": "/finetune_demo/evaluate_cogvlm_demo.py:92-116", "hash": "ac652ec87c144c7b910a711e1ebbb409", "title": "Evaluate Model's Predictions"}, "144": {"path": "/finetune_demo/evaluate_cogvlm_demo.py:117-147", "hash": "b1d2972087ac2b46866407ce15ba00c0", "title": "Calculate Accuracy of Model Predictions"}, "145": {"path": "/finetune_demo/evaluate_cogvlm_demo.py:148-170", "hash": "ddeaeaec5c08db2e9e0234d710d645e4", "title": "Data Preprocessing for Autoregressive Model Prediction"}, "146": {"path": "/finetune_demo/evaluate_cogvlm_demo.py:171-199", "hash": "e1338eac379e66a4767417a0f1eca013", "title": "Forward Step and Dataset Creation in ML Model"}, "147": {"path": "/finetune_demo/evaluate_cogvlm_demo.py:200-215", "hash": "8c8895e065b906680189a3f9d33b0721", "title": "Preparing Model for Fine-tuning"}, "148": {"path": "/finetune_demo/evaluate_cogvlm_demo.py:216-219", "hash": "0aa13b3cc9d8ddc141dea5d9d1de6f3b", "title": "Evaluating Model Performance with Image and Text Processors"}, "149": {"path": "/finetune_demo/finetune_cogagent_demo.py", "hash": "27873d9f10865b2493c1fc1eee11ebfc", "title": "Model Fine-Tuning Demo"}, "150": {"path": "/finetune_demo/finetune_cogagent_demo.py:1-26", "hash": "84796ec9f259f3aa98fc11a8b5aece67", "title": "Enable Training for Specific Layers"}, "151": {"path": "/finetune_demo/finetune_cogagent_demo.py:27-55", "hash": "9b96f9fa19e0ee553dd28a64fc4ddb42", "title": "Filter and Count Trainable Parameters"}, "152": {"path": "/finetune_demo/finetune_cogagent_demo.py:56-76", "hash": "714b9c1dcc145d24c8945d49ddd9053c", "title": "Lists to Tensors and Attribute Extraction"}, "153": {"path": "/finetune_demo/finetune_cogagent_demo.py:77-109", "hash": "cdd6fa22156c77e7970c1c9ab729833a", "title": "Finetune COG Agent Model Function Code"}, "154": {"path": "/finetune_demo/finetune_cogagent_demo.py:110-140", "hash": "517f587e141bfde68750164081a18f3b", "title": "Batch Data Loader and Converter"}, "155": {"path": "/finetune_demo/finetune_cogagent_demo.py:141-165", "hash": "45da0dcbb0f5a4a6929a41ceeb2acd6e", "title": "Token Concatenation and Decoding"}, "156": {"path": "/finetune_demo/finetune_cogagent_demo.py:166-195", "hash": "d5fe55622b6a661fad19e31a8f0817a7", "title": "Accuracy Metrics Calculator"}, "157": {"path": "/finetune_demo/finetune_cogagent_demo.py:196-217", "hash": "651ea550c48b38a11b475926c38bea5e", "title": "Fine-Tuning and Generating Outputs"}, "158": {"path": "/finetune_demo/finetune_cogagent_demo.py:220-244", "hash": "35963f68d863c72d3994187f3fea4645", "title": "Defining Neural Network Functions"}, "159": {"path": "/finetune_demo/finetune_cogagent_demo.py:245-263", "hash": "03855130919af7e5b6cf2f8fa281f077", "title": "Fine-tune CogAgent Model using Argparse and LoraMixin"}, "160": {"path": "/finetune_demo/finetune_cogagent_demo.py:265-278", "hash": "c761c43ba0bf5894b7fc8c190a8342f9", "title": "Initiate CogAgent Fine-Tuning Model"}, "161": {"path": "/finetune_demo/finetune_cogagent_demo.py:279-290", "hash": "36d568d4aef1916f4b7ab0e2c1597e75", "title": "Model Training and Merging Process"}, "162": {"path": "/finetune_demo/finetune_cogagent_lora.sh", "hash": "0f3561b31c1fc59c9548347d172715a3", "title": "Finetune CogAgent with LORA and Deepspeed"}, "163": {"path": "/finetune_demo/finetune_cogagent_lora.sh:1-36", "hash": "3a60baa74aa0af41d0bbd8790a5dc432", "title": "CUDA, LD_LIBRARY_PATH Setup for Model Training"}, "164": {"path": "/finetune_demo/finetune_cogagent_lora.sh:37-59", "hash": "ec789099d7f60ee60183d9298f1bf380", "title": "Finetuning CogAgent with Deepspeed and VIT"}, "165": {"path": "/finetune_demo/finetune_cogvlm_demo.py", "hash": "41d8204de1e20f51ded2775162dc8050", "title": "Finetune CogVLM Chatbot Demo"}, "166": {"path": "/finetune_demo/finetune_cogvlm_demo.py:1-29", "hash": "3519300ff0b48e572bca4c748dea9607", "title": "Fine-tuning CogVLM with Disable Functions"}, "167": {"path": "/finetune_demo/finetune_cogvlm_demo.py:30-55", "hash": "22a670082f51e8df04d401c4a302ecdd", "title": "Defining data_collator Function"}, "168": {"path": "/finetune_demo/finetune_cogvlm_demo.py:56-91", "hash": "52a741cef4d8eecd0904745b12d93f5d", "title": "Tensor Data Processing Function"}, "169": {"path": "/finetune_demo/finetune_cogvlm_demo.py:92-119", "hash": "4768cbd72371a4cd8ff4b14930bf5f7b", "title": "Generate Model Responses"}, "170": {"path": "/finetune_demo/finetune_cogvlm_demo.py:119-142", "hash": "c58234c3893572914637b90d3eb0865e", "title": "Strategic Model Filling Sequence Called"}, "171": {"path": "/finetune_demo/finetune_cogvlm_demo.py:143-173", "hash": "d6e5b039df03983adca1f53df0ee6b6f", "title": "Case-Sensitive Accuracy Calculator"}, "172": {"path": "/finetune_demo/finetune_cogvlm_demo.py:174-196", "hash": "96e55ada1eaf03bc94301863bb58d5af", "title": "Finetune CogVLM Model for Specific Task"}, "173": {"path": "/finetune_demo/finetune_cogvlm_demo.py:197-226", "hash": "ae5564e91e0cc05b29d2188e740ff993", "title": "Forward Pass for Language Model Demo"}, "174": {"path": "/finetune_demo/finetune_cogvlm_demo.py:227-241", "hash": "c7915aaed042ec406b1c667f2896423e", "title": "Command Line Arguments for CogVLM Model Training"}, "175": {"path": "/finetune_demo/finetune_cogvlm_demo.py:242-256", "hash": "e4a63ce27b18dcb281fed52fddb7ae1c", "title": "Model Finetuning Demo"}, "176": {"path": "/finetune_demo/finetune_cogvlm_demo.py:256-263", "hash": "c62e3859b9f56c08344ea2745dec808f", "title": "LORA Fine-tuning Demo"}, "177": {"path": "/finetune_demo/finetune_cogvlm_lora.sh", "hash": "871771e5a575bcfb5167c406f4d2685e", "title": "Fine-tune CogVLM with LORA and Parallelism"}, "178": {"path": "/finetune_demo/finetune_cogvlm_lora.sh:1-36", "hash": "356377e3a2891417505ed38e624df559", "title": "Finetuning CogVLM with LORA and Parallelism"}, "179": {"path": "/finetune_demo/finetune_cogvlm_lora.sh:37-59", "hash": "17208c7d8982f915838d049c0de0990e", "title": "Fine-tuning CogVLM with DeepSpeed and LORA"}, "180": {"path": "/finetune_demo/test_config_bf16.json", "hash": "a7498e60908612cc85733a3fb42eb57f", "title": "BF16 Batch Finetuning Config"}, "181": {"path": "/openai_demo/openai_api.py", "hash": "5a5492352ab95ec0e26a60e9f22fa2ff", "title": "FastAPI Chat App with OpenAI Integration"}, "182": {"path": "/openai_demo/openai_api.py:1-32", "hash": "d672d326bc3bdc448f63cb4304a4a449", "title": "Library Import and Configuration"}, "183": {"path": "/openai_demo/openai_api.py:34-68", "hash": "174c238eadd8d7eea30edd6aece91005", "title": "Model Card Class and FastAPI with GPU Memory Management"}, "184": {"path": "/openai_demo/openai_api.py:71-118", "hash": "618a8a503fdf5ef75b886397ba41b0a4", "title": "OpenAI Chat Response Generator"}, "185": {"path": "/openai_demo/openai_api.py:121-152", "hash": "b55a8eb6268392b6d2b4125032403866", "title": "OpenAI API: Model Listing and Response Classes"}, "186": {"path": "/openai_demo/openai_api.py:155-185", "hash": "65149d9f8fa9f57701382d440d6fab4c", "title": "Chat Completion Route\n\nExplanation: This title summarizes the creation of a POST route for chat completions, highlighting the main function performed in the given code section"}, "187": {"path": "/openai_demo/openai_api.py:186-211", "hash": "b825240641233879332a7c7f85691b1d", "title": "Streaming Predictions with OpenAI API"}, "188": {"path": "/openai_demo/openai_api.py:212-235", "hash": "7543b3f599c903f68be313e3c2b20357", "title": "OpenAI Chat Assistant with CogVLM Model"}, "189": {"path": "/openai_demo/openai_api.py:236-265", "hash": "288f1d2a890df1dd459d78f6f296eb16", "title": "Text and Image Extraction API"}, "190": {"path": "/openai_demo/openai_api.py:266-287", "hash": "662815a0a2e102cda7e4c7d706a8052c", "title": "Message History Processing"}, "191": {"path": "/openai_demo/openai_api.py:288-312", "hash": "7d41f96369fc97965353b9be12744e50", "title": "Streaming Conversation Generation with CogVLM"}, "192": {"path": "/openai_demo/openai_api.py:313-335", "hash": "369460c6c2cc9adc04ac29084ace85e5", "title": "Prepare Input and Set Streamer for Language Model"}, "193": {"path": "/openai_demo/openai_api.py:336-373", "hash": "533e95c317e64cd7fdfb9bf755f222cd", "title": "AI-Generated Text with Memory Cleanup"}, "194": {"path": "/openai_demo/openai_api.py:374-400", "hash": "62a010a2603a0fb5b7f93bb50f4c91a0", "title": "CUDA Device Check and Model Instantiation"}, "195": {"path": "/openai_demo/openai_api_request.py", "hash": "549336a1c08ec83482ac3b9a382e0791", "title": "OpenAI API Chat Simulator"}, "196": {"path": "/openai_demo/openai_api_request.py:1-23", "hash": "4b1a318347e7922954e6035d6ff98a19", "title": "OpenAI API Mimic for CogVLM and CogAgent Chat"}, "197": {"path": "/openai_demo/openai_api_request.py:24-49", "hash": "a05f0b6a223009408840b547c49ba0c9", "title": "OpenAI API Request Function"}, "198": {"path": "/openai_demo/openai_api_request.py:50-82", "hash": "356ddcace75ab46b7d665033e31dd22e", "title": "OpenAI API Request and Image Encoding"}, "199": {"path": "/openai_demo/openai_api_request.py:83-108", "hash": "6d67ff435d6caf637f648b854d199dda", "title": "Chatbot Image Prompting with OpenAI API"}, "200": {"path": "/openai_demo/openai_api_request.py:108-119", "hash": "eec3c512b0f16cb80e53e4723a6c4dcb", "title": "OpenAI Chatbot Image Description and Season Query"}, "201": {"path": "/requirements.txt", "hash": "15cd7a91d449ed2c14fc14330af068b5", "title": "Python Project Requirements"}, "202": {"path": "/utils/merge_model.py", "hash": "17717f0e70be12e1c49183406874fa0e", "title": "Merging and Fine-tuning Model Checkpoint"}, "203": {"path": "/utils/merge_model.py:1-27", "hash": "f471226e472380e8bd563042ca7c56e3", "title": "Loading and Fine-Tuning Model"}, "204": {"path": "/utils/merge_model.py:28-42", "hash": "91b6a6eba5e6014208bbd1352606b4ab", "title": "Distributed Model Training and Checkpoint Saving"}, "205": {"path": "/utils/models/__init__.py", "hash": "f98cf23f2b1d3d45a288f4ebc2a0f575", "title": "Import Models and Functions"}, "206": {"path": "/utils/models/cogagent_model.py", "hash": "5d8e8d6c8371c209cb313f20c0c7410d", "title": "CogAgent Model: Vision Transformer Fine-Tuning"}, "207": {"path": "/utils/models/cogagent_model.py:1-27", "hash": "a9a653a57ab055a8426e7cf2b7afe162", "title": "GLU Module for CogAgent Model"}, "208": {"path": "/utils/models/cogagent_model.py:29-59", "hash": "04670d7d130c4793db2eb99ae62f4f84", "title": "Simplified Model Argument Parsing"}, "209": {"path": "/utils/models/cogagent_model.py:60-82", "hash": "f003043015f82c41b7c4025e7560b8de", "title": "VIT Model Initialization with External Vision Integration"}, "210": {"path": "/utils/models/cogagent_model.py:83-108", "hash": "a35e0597c8302064a9eaa837a33069c6", "title": "VIT Model with Position Embedding Initialization"}, "211": {"path": "/utils/models/cogagent_model.py:109-135", "hash": "ebd8b2e4881f154080701988a8efff03", "title": "ImageMixin: EVA2CLIP Model Setup"}, "212": {"path": "/utils/models/cogagent_model.py:136-155", "hash": "827fc4fe2a27b2b00c9dedf73b3de99f", "title": "Multi-Modal Embedding in COG-VLM Model"}, "213": {"path": "/utils/models/cogagent_model.py:157-175", "hash": "5d936c64b35792d0c68c4919af87f43e", "title": "CogAgent Model: LLaMA-based Image Cognet Model"}, "214": {"path": "/utils/models/cogagent_model.py:176-195", "hash": "bd13c9486f5c5c4c83fdd8f1d654b64a", "title": "Cross-Attention Model Parameters"}, "215": {"path": "/utils/models/cogagent_model.py:196-214", "hash": "317dd61c25ccb1d4ed7ca64648ef2b25", "title": "Fine-tuning CogAgent Model: Class and Initializer"}, "216": {"path": "/utils/models/cogagent_model.py:215-229", "hash": "70517210997212edf4fd2ba9262a2ad8", "title": "Initializing FineTuneTest Model"}, "217": {"path": "/utils/models/cogagent_model.py:230-241", "hash": "d129afd2602aa0f25a33b70d71715a28", "title": "CogAgent Finetune Parser Customization"}, "218": {"path": "/utils/models/cogvlm_model.py", "hash": "4a0ac330fd2e0f346d6c6faa254358a1", "title": "Fine-tuning CogVLM with Mixins"}, "219": {"path": "/utils/models/cogvlm_model.py:1-25", "hash": "147240c9e4a7caddaa72aced8bcc5958", "title": "CogVLM Language Model Setup"}, "220": {"path": "/utils/models/cogvlm_model.py:26-56", "hash": "91ad1d0d322b15091c7cb92713ebf40c", "title": "CogVLM Model Definition"}, "221": {"path": "/utils/models/cogvlm_model.py:57-78", "hash": "95e5adf48889ae979feede65608db028", "title": "Initialize EVA2CLIP Model"}, "222": {"path": "/utils/models/cogvlm_model.py:79-96", "hash": "7b963f160d6fa9dad3efcfbd737b7371", "title": "Vision-Guided Word Embedding"}, "223": {"path": "/utils/models/cogvlm_model.py:97-117", "hash": "1293260b023681eb0a9830f11ae5f36d", "title": "CogVLM Model Initialization"}, "224": {"path": "/utils/models/cogvlm_model.py:118-135", "hash": "530aec977cac672f6ead8e62839b95d5", "title": "Fine-TuneTrain Model Initialization"}, "225": {"path": "/utils/models/cogvlm_model.py:136-151", "hash": "4fdeae6c14e4a8419776e42869f18250", "title": "Fine-tuning Mixins for CogVLM Model"}, "226": {"path": "/utils/models/cogvlm_model.py:152-165", "hash": "0813fd2d2ebee7bacf84c89018af301d", "title": "CogVLM Finetuning Arguments"}, "227": {"path": "/utils/models/eva_clip_L_hf.py", "hash": "89b06bd9e55f901eb4beab461c3e00cf", "title": "EvaCLIP and Position Embedding: Vision Transformer Models"}, "228": {"path": "/utils/models/eva_clip_L_hf.py:1-20", "hash": "ee07bbf78e92be0fb240785c61089c3b", "title": "Broadcasting Tensor Concatenation"}, "229": {"path": "/utils/models/eva_clip_L_hf.py:21-54", "hash": "782b62a1a68a47dd48d333f13891689b", "title": "Rotary Position Embedding Class"}, "230": {"path": "/utils/models/eva_clip_L_hf.py:55-80", "hash": "ad7279372f7b669084a8c7e9a4a4057a", "title": "Efficient Fourier Transform Implementation"}, "231": {"path": "/utils/models/eva_clip_L_hf.py:81-115", "hash": "501614bb07e393ef62d471369857dedc", "title": "Dropout Patches in EvaClip Model"}, "232": {"path": "/utils/models/eva_clip_L_hf.py:116-150", "hash": "b949fe500d60aab23028b04e259ed8e1", "title": "Masking Patches in Input Tensors"}, "233": {"path": "/utils/models/eva_clip_L_hf.py:151-189", "hash": "392eb45cf770f6175330c5554bd3c22d", "title": "DropPath and Mlp: Neural Network Modules"}, "234": {"path": "/utils/models/eva_clip_L_hf.py:190-223", "hash": "88c3f2c0b421cf041f3bbe850b3e15fd", "title": "Eva Clip L: Neural Network Layer with Fc, Act, Ffn, Dropout"}, "235": {"path": "/utils/models/eva_clip_L_hf.py:224-254", "hash": "5ef71e565afa18c1f8e928a6b1f81cb4", "title": "Efficient Vision Transformer Model"}, "236": {"path": "/utils/models/eva_clip_L_hf.py:255-276", "hash": "2e798780954ffcb845466933676651c2", "title": "Initialize MultiHeadAttention Layers"}, "237": {"path": "/utils/models/eva_clip_L_hf.py:277-290", "hash": "bf215cbe75664faf20f986ab1d45748e", "title": "Relative Coordinates Indexing and Labeling"}, "238": {"path": "/utils/models/eva_clip_L_hf.py:292-315", "hash": "c08726595005f3daf055eb7bb2b235c2", "title": "Self-Attention Mechanism Class"}, "239": {"path": "/utils/models/eva_clip_L_hf.py:316-340", "hash": "0d50dcd74cd52df5bbd6b83b685a9c20", "title": "Transformer Tensor Processing"}, "240": {"path": "/utils/models/eva_clip_L_hf.py:341-364", "hash": "2493407d7f83774f8a8d98ce12457ea4", "title": "Efficient Multi-Head Attention with Dropout"}, "241": {"path": "/utils/models/eva_clip_L_hf.py:365-390", "hash": "0e6847e94d4dc46534c7ef460122c353", "title": "Transformer Block Definition"}, "242": {"path": "/utils/models/eva_clip_L_hf.py:391-415", "hash": "58311aa6a6c0e268b3a6afa24ca458ff", "title": "Transformer Model Class Definition"}, "243": {"path": "/utils/models/eva_clip_L_hf.py:416-435", "hash": "6315711af18b845d2e0a5ca8ca1d59cc", "title": "Defining Forward Function for Transformer Model"}, "244": {"path": "/utils/models/eva_clip_L_hf.py:436-460", "hash": "695be0d157b9a62a20a9c3eed09f4dff", "title": "Eva Clip L Hf Model: Drop Path MLP Architecture"}, "245": {"path": "/utils/models/eva_clip_L_hf.py:461-481", "hash": "d1103f68982d563f1a03fc136aab6d6e", "title": "Relative Position Bias Initialization"}, "246": {"path": "/utils/models/eva_clip_L_hf.py:482-501", "hash": "b1352dc7f6998bc4c59014710c6cfbc2", "title": "Position Bias Table Generation"}, "247": {"path": "/utils/models/eva_clip_L_hf.py:502-516", "hash": "01468a4d4b109592ec2c77eb141b58e8", "title": "Initializing Vision Transformer Model"}, "248": {"path": "/utils/models/eva_clip_L_hf.py:517-544", "hash": "8c55279ad56de139ce22ae57bf96d994", "title": "Initializing Transformer Model Attributes"}, "249": {"path": "/utils/models/eva_clip_L_hf.py:546-562", "hash": "c18aa389c25700d194055df1c1fa4e13", "title": "EvaClip: Model Block Creation and Initialization"}, "250": {"path": "/utils/models/eva_clip_L_hf.py:563-589", "hash": "c99b0ddfc955b2381e5df8e53a97c7ba", "title": "Weight Initialization and Dropout Configurator"}, "251": {"path": "/utils/models/eva_clip_L_hf.py:590-621", "hash": "a8ede4b6ee41c45f56b9611f1248731c", "title": "EvaClip Model Utilities"}, "252": {"path": "/utils/models/eva_clip_L_hf.py:622-642", "hash": "2e07b480597631a1c746d5c975a0f7e0", "title": "Linear Layer with Patch Dropout"}, "253": {"path": "/utils/models/eva_clip_L_hf.py:643-674", "hash": "6d7b4e50d2b151810c6296d0488e4bb1", "title": "LayerNorm Subclass with Blocks and Patch Dropout"}, "254": {"path": "/utils/models/eva_clip_L_hf.py:675-696", "hash": "ffe969af06e55d5053cf4432257972ca", "title": "CLIP Vision Model Config Class"}, "255": {"path": "/utils/models/eva_clip_L_hf.py:697-722", "hash": "2ecab14b31628f00a5c7c1c23ee2155f", "title": "Build Vision Tower in CLIP Model"}, "256": {"path": "/utils/models/eva_clip_L_hf.py:723-744", "hash": "75f2e55d0ba3bbf1583ffabbc729bc6e", "title": "Initialize EVAVisionTransformer Model"}, "257": {"path": "/utils/models/eva_clip_L_hf.py:745-779", "hash": "1556e0b1530643b343066b61c75e7116", "title": "Eva2LargeEncoder: Vision Transformer Features"}, "258": {"path": "/utils/models/eva_clip_L_hf.py:780-790", "hash": "e002996ca6d2696560c2c9e1ce35430b", "title": "Cross Vision Model with Eva2LargeEncoder and Position Embedding"}, "259": {"path": "/utils/models/eva_clip_model.py", "hash": "ecaf8f647da5f424f1dd8ab8a0767891", "title": "Efficient Transformer Model: EVA2CLIP"}, "260": {"path": "/utils/models/eva_clip_model.py:1-26", "hash": "1e322112ca9704d62df6a7d504347d53", "title": "Self-Attention Mapping Mixin"}, "261": {"path": "/utils/models/eva_clip_model.py:28-52", "hash": "e1ef12a883b365c3fc72297c10c13c57", "title": "Memory-Efficient Attention Functions"}, "262": {"path": "/utils/models/eva_clip_model.py:53-79", "hash": "c0bd1858867f36804ec95d4be92f9cb2", "title": "Forward Pass: Transformer Layer Attention"}, "263": {"path": "/utils/models/eva_clip_model.py:80-99", "hash": "b687af9a3eee60e039a59e7072bd772b", "title": "Efficient Video Analysis Model"}, "264": {"path": "/utils/models/eva_clip_model.py:100-119", "hash": "0478396c7260d6a25cafcd985227f0aa", "title": "EVA2CLIP Model Initialization"}, "265": {"path": "/utils/models/eva_clip_model.py:120-126", "hash": "453f8d289f6fb555f7eb799346b32d8b", "title": "Configure Argument Groups for EVA2CLIP"}, "266": {"path": "/utils/models/mixin.py", "hash": "3adfded0e6a5a51d59b185220ff3ef8f", "title": "Transformer Layer Mixins"}, "267": {"path": "/utils/models/mixin.py:1-25", "hash": "fef2f21fb96196937dbd93b4250664f7", "title": "LlamaVisionExpertFCMixin Initialization"}, "268": {"path": "/utils/models/mixin.py:26-58", "hash": "f84479e23773f7b2202c07ff2630281c", "title": "VisionTransformer Layer Configuration"}, "269": {"path": "/utils/models/mixin.py:59-88", "hash": "6aa1bdc2c32d46a9910b895c2ef26642", "title": "Parallel Layers Initialization"}, "270": {"path": "/utils/models/mixin.py:89-110", "hash": "d69453fe3960dd87fc78657298064604", "title": "Vision Expert Transformer Mixin Class"}, "271": {"path": "/utils/models/mixin.py:111-124", "hash": "19fa4a2ea749c4300ebc5dbf6bd516d9", "title": "Tensor Masking Mixin"}, "272": {"path": "/utils/models/mixin.py:125-145", "hash": "22cc9f7e584f33e03d3617a99356f890", "title": "LlamaVisionExpertAttnMixin Class Definition"}, "273": {"path": "/utils/models/mixin.py:146-169", "hash": "eeb1143335656d634ee4f2694522eb97", "title": "Model Parameters Initialization"}, "274": {"path": "/utils/models/mixin.py:170-198", "hash": "3014e84383a536478a2b2adf93712589", "title": "Linear Layers for Query, Key, and Value Projections"}, "275": {"path": "/utils/models/mixin.py:200-221", "hash": "1ad4a79d40d2570882a98146fc422d65", "title": "Vision Attention Mixin Module Dictionary"}, "276": {"path": "/utils/models/mixin.py:222-238", "hash": "dae04189449955bfc0c09af38273c6db", "title": "Separate Language and Vision States"}, "277": {"path": "/utils/models/mixin.py:239-256", "hash": "dd9536c9fb4f669f41e3b3300db04fb6", "title": "Multi-Head Attention with Rotary Embeddings"}, "278": {"path": "/utils/models/mixin.py:257-274", "hash": "d22569248b5ecd724d2302c12b991686", "title": "Transformer Model Parallelism with Vision and Language Experts"}, "279": {"path": "/utils/split_dataset.py", "hash": "8a5debf1ede3f146f9256b0ae71f694f", "title": "Dataset Splitter Utilities"}, "280": {"path": "/utils/split_dataset.py:1-34", "hash": "931ece44389a8530817b9358104e5372", "title": "Shuffle and Split Dataset"}, "281": {"path": "/utils/split_dataset.py:35-35", "hash": "bfdf8ef6b7a1b6f56313f60fdb049ecc", "title": "Task Completion Message"}, "282": {"path": "/utils/utils/__init__.py", "hash": "2e18333f217a6001ed15fbc899a12827", "title": "Multi-task Utility Module"}, "283": {"path": "/utils/utils/chat.py", "hash": "eb69621e16f1de32a4b502285b3bb63b", "title": "Efficient Image Processing Utility"}, "284": {"path": "/utils/utils/chat.py:1-30", "hash": "ee921a4a7a662ab6b673059025aada65", "title": "Image Data Processor"}, "285": {"path": "/utils/utils/chat.py:31-55", "hash": "15dd2948065c7ce4859ac52dd6ff0934", "title": "Image Processing Function"}, "286": {"path": "/utils/utils/chat.py:56-72", "hash": "b706d5b4b37dbc13a394a8285bcaef97", "title": "Data Type Conversion and Device Placement"}, "287": {"path": "/utils/utils/chat.py:74-88", "hash": "063788bd416f7f9c78a60b56febd3191", "title": "Input Validation and Padding"}, "288": {"path": "/utils/utils/chat.py:89-114", "hash": "fd6f8e13b3ddb8ca22b41486d400ac55", "title": "Stream-filling Prediction Modification"}, "289": {"path": "/utils/utils/chat.py:115-142", "hash": "1de90946293bb711e0a329719b5a3cd9", "title": "Chat Response Processing and Formatting"}, "290": {"path": "/utils/utils/chat.py:143-149", "hash": "1bb7905e67dd790b4779fbcf807c2bc6", "title": "Process and Parse Response"}, "291": {"path": "/utils/utils/dataset.py", "hash": "3d55a19acbc9541ac94c26e27a89b3b6", "title": "Custom PyTorch Dataset Loader"}, "292": {"path": "/utils/utils/dataset.py:1-29", "hash": "53636c4fdd69196e22a5acf2cdc55af1", "title": "Image Text Dataset Generator"}, "293": {"path": "/utils/utils/dataset.py:30-60", "hash": "d5de880ce03ebe83e9ecf99ebba0f176", "title": "Load and Preprocess Images from Data Directory"}, "294": {"path": "/utils/utils/dataset.py:61-61", "hash": "2594255f2630d8dd21d70ca9bacd607a", "title": "Dataset Return Function"}, "295": {"path": "/utils/utils/grounding_parser.py", "hash": "dddca66953f5fba57de81f69d09cd5a9", "title": "Overlay Images with Text"}, "296": {"path": "/utils/utils/grounding_parser.py:1-27", "hash": "017632e84f8800db258a5458ff40274f", "title": "Box Overlay Image Generator"}, "297": {"path": "/utils/utils/grounding_parser.py:28-49", "hash": "0d6cb8ebf48786b3108aea012a640a94", "title": "Text Overlay Image Saving"}, "298": {"path": "/utils/utils/grounding_parser.py:50-76", "hash": "a50f709dfc88701599dfc8fff619cae5", "title": "Noun Phrase Bounding Box Dictionary"}, "299": {"path": "/utils/utils/grounding_parser.py:77-86", "hash": "4196475c8842352b65e2ca534277a6e3", "title": "Box Position Parser"}, "300": {"path": "/utils/utils/language.py", "hash": "32a2a28cb62933c7e3f21ec7f23e97ab", "title": "Tokenization and Preprocessing for Language Models"}, "301": {"path": "/utils/utils/language.py:1-28", "hash": "4c05dda6c36554454d756be32a10ee5f", "title": "Chat and VQA History to Prompt Converter"}, "302": {"path": "/utils/utils/language.py:29-63", "hash": "4b5c057e29c7dadbee13ba846bb50bfd", "title": "Llama2 Tokenizer and Text Processor"}, "303": {"path": "/utils/utils/language.py:64-83", "hash": "91c3c058a2ff80d9120e0fdf063b81f7", "title": "Preparing Inputs for Language Models"}, "304": {"path": "/utils/utils/language.py:84-107", "hash": "4f19102c5141a2ab44b42ce3f89bf063", "title": "Preprocessing Input Sequence for Embedding and Vision"}, "305": {"path": "/utils/utils/language.py:108-130", "hash": "85b480a5c88412269126dcd0ca3f4234", "title": "Prepping Input Data for Model"}, "306": {"path": "/utils/utils/language.py:131-146", "hash": "1cd8bd40f5d8313dba7def05cc0441cd", "title": "Text Processing Utilities"}, "307": {"path": "/utils/utils/language.py:148-173", "hash": "e6c17bbcf6952c492f322d89b0104dd8", "title": "Mask and Position ID Creation Function"}, "308": {"path": "/utils/utils/language.py:174-200", "hash": "36df118dd3767903b0f22a939241c7be", "title": "Image Caption Tokenizer Setup"}, "309": {"path": "/utils/utils/language.py:201-223", "hash": "4ada756228aefb10c3907033a98a1e65", "title": "Prepare Input for Language Model"}, "310": {"path": "/utils/utils/language.py:224-238", "hash": "bcc67b4624c888aa933649b51c9c62c2", "title": "Functions for Image Retrieval"}, "311": {"path": "/utils/utils/vision.py", "hash": "14ffcb88f1ed2ae543380f574493b0fa", "title": "Blip Image Processing Utils"}, "312": {"path": "/utils/utils/vision.py:1-31", "hash": "0ae62cce42e8903445c67adf917ba70e", "title": "BlipImageEvalProcessor: Image Preprocessing in Torchvision"}, "313": {"path": "/utils/utils/vision.py:33-34", "hash": "d8d12662483777ad9008055193a715e1", "title": "Image Processor Factory"}}}